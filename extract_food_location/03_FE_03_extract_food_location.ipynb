{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "from typing import Dict, Any, Optional, List\n",
    "import random\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to store the name of food and location in the video\n",
    "FOOD_LOCATION_FOLDER = 'food_location'\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(FOOD_LOCATION_FOLDER):\n",
    "    os.makedirs(FOOD_LOCATION_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu vào dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14252 entries, 0 to 14251\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   video.id    14252 non-null  object\n",
      " 1   desc        14252 non-null  object\n",
      " 2   transcript  13430 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 334.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load data from parquet file\n",
    "# video_df = pd.read_parquet(\"top_20_percent_weekly_videos_transcripts.parquet\")\n",
    "video_df = pd.read_parquet(\"small_weekly_videos_transcripts.parquet\")\n",
    "\n",
    "# # Sort data by \"statsV2.playCount\" in descending order\n",
    "# # then reset the index to start from 0\n",
    "# video_df = video_df.sort_values(\n",
    "#     by=\"statsV2.playCount\",\n",
    "#     ascending=False\n",
    "# ).reset_index(drop=True)\n",
    "\n",
    "video_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuẩn bị xử lý dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 14252)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_range = range(video_df.shape[0])[0:20_000]\n",
    "video_id_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Danh sách các API để chạy luân phiên\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_list = [\n",
    "    # \"AIzaSyCgr0Af_ph5vvql_VXpyIwfumJOaehbLDo\",  # vmphat.24\n",
    "    \"AIzaSyAAmXLg2yM3Ygz3B_HYC4fcE1iJDNFhxm0\",  # pvminh\n",
    "    \"AIzaSyAB9vrQbQPxOp1tbYWN9hjmmmno-9uGwR0\",  # ngocquynh\n",
    "    \"AIzaSyCArspeWWKenZy4QSQlpBIrUAnXCWPRr90\",  # kiet\n",
    "    \"AIzaSyBMcY_CGvsXGJSOMu3vLfWsd4-qL0bQflg\",  # franie\n",
    "    \"AIzaSyAL9WZ2mO88O6DuwivJJWK2oqcy9_UXBNQ\",  # daniel\n",
    "    \"AIzaSyDrD1yVeRW85VxX433JKFxKbtFuQ83UhMo\",  # tulin\n",
    "    \"AIzaSyA8DDmJgizVgSiE2MdjnVpDZEXqTjEgBRg\",  # martin\n",
    "\n",
    "    # \"AIzaSyAcvcAtAlMW4QD1OzCoIsmZl04qjFZ_AZo\",  # khdludteam5\n",
    "    # \"AIzaSyCbs_KHkUr-BWL9X6_06kZb3brG7UI1a6w\",  # vmphat21\n",
    "\n",
    "    \"AIzaSyBrTgG4YDzJMuK9WknMTbdnnoskSX1nvMY\",  # pr\n",
    "\n",
    "    # \"AIzaSyDyjL0w1m1dWCNOP7_9UYXDQnNOqbAdbCw\",  # vmphat.24\n",
    "    \"AIzaSyAHiAgc7tIuq4YKtswB-AaHa0W9eqQ5jGw\",  # pvminh\n",
    "    \"AIzaSyCnUToo7FRJn8v3BwMOt3FWwrDDFf2b4UI\",  # ngocquynh\n",
    "    \"AIzaSyCAnhUoYz6YAYCSfSFF-JmGNbMdxzhDKYU\",  # kiet\n",
    "    \"AIzaSyBqu4Xbby4sc0vsCUbxhjqYcqOwKKAwaT4\",  # franie\n",
    "    \"AIzaSyDh32FdRtHzuRUaZUXafcmlPHqYQtbRx3A\",  # daniel\n",
    "    \"AIzaSyBRhc3Q6rdz3Ok93V5xB76Lfk3mNtdzQEI\",  # tulin\n",
    "    \"AIzaSyDPUFWmBABBPAYEa_lOkeony8C2eqKkXTw\",  # martin\n",
    "    \"AIzaSyAY8nfoP7DXfL571ovT8V_HlMWCTdHqdgc\",  # khdludteam5\n",
    "    \"AIzaSyC4WprE1HsmCUwOoGi4HFfA1Lzg5XSE0Cg\",  # vmphat21\n",
    "\n",
    "    \"AIzaSyC-letXWg8hVdOA8H6BlEXb-TXF7W7twQM\",\n",
    "    \"AIzaSyCmJQlfuGKf2FNvrUWYd-fPuxYRcmm3p4Q\",\n",
    "    \"AIzaSyDlKoywc1dVIaiv4UGVDc0OuaEBFluS2IU\",\n",
    "    \"AIzaSyDk5UZkrHP6H3fgAI0FidWJKcVptQdEWBE\",\n",
    "    \"AIzaSyBkVUkCK_mMBhJnyi9KoZ9WFf1tfJnlOac\",\n",
    "    \"AIzaSyATHBdVQsH-7J8M2v6UcciZyWbzkr13uTA\",\n",
    "    \"AIzaSyAvAt0as8Zs0r_iustkbWyimOhdLOzCm8w\",\n",
    "    \"AIzaSyDaUPT6NQS8sqs16_hm9_A8ONHsVbh8QiY\",\n",
    "\n",
    "\n",
    "    \"AIzaSyAdbNfxlQQQjKSgAcOjQt-XUwil-FMl6V8\",  # Luc - Ca nhan\n",
    "    \"AIzaSyCSGNpc1IlacTUwN31TKWms0RzF_we17vk\",  # Luc - Truong\n",
    "\n",
    "    \"AIzaSyBE8VObttX0oOGz5Jd82AtOiLTSzavIBL8\",\n",
    "    \"AIzaSyAo5sCKOhGgYNgJ0m1QKsT29Ov-GNQHeSo\",\n",
    "    \"AIzaSyDLa5CYtBGeXoV1-8y_ojA9eR_xzONABew\",\n",
    "    \"AIzaSyCUtzli8ZRql653-0u_RrL7zM2SgEdb5ss\",\n",
    "    \"AIzaSyBPi15fdt_YtyqaBIEuvSQ66T6T0ROHEA4\",\n",
    "    \"AIzaSyC3DhYcDb8sLzzwywoJe8Foki3kMnVKPwQ\",\n",
    "    \"AIzaSyDRE-VA4R9-UBRekhCGCcy3NlhlwQa1fnU\",\n",
    "    \"AIzaSyD-WsC4RABxdqebovU-TYMueMHxPT2l6Nw\",\n",
    "\n",
    "    \"AIzaSyDBscWgL9o2QtfNvx_xnZP3CWweyknGJKM\",  # han-asd\n",
    "    \"AIzaSyAhbb5IEibxRDH8a8XB8Zk7lopPh8jhgwI\",  # han-len\n",
    "]\n",
    "\n",
    "assert len(api_list) == len(set(api_list)), \"Duplicate API keys found\"\n",
    "n_apis = len(api_list)\n",
    "api_request_threshold = 14\n",
    "api_idx = random.randint(0, n_apis - 1)\n",
    "n_consecutive_requests = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lấy danh sách các video đã được xử lý\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text file to get a set of video IDs that have been preprocessed\n",
    "preprocessed_video_ids = set()\n",
    "if os.path.exists(\"preprocessed_video_ids.txt\"):\n",
    "    with open(\"preprocessed_video_ids.txt\", \"r\") as f:\n",
    "        preprocessed_video_ids = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos already preprocessed: 14252\n"
     ]
    }
   ],
   "source": [
    "# Print the number of videos that have been preprocessed\n",
    "print(f\"Number of videos already preprocessed: {len(preprocessed_video_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các hàm tiện ích\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phân tích nội dung sau (từ transcript video hoặc mô tả) và trích xuất thông tin:\n",
    "{text}\n",
    "\n",
    "Phân tích và trích xuất các thông tin theo cấu trúc dưới đây:\n",
    "Bước 1: Phân loại Video (dựa trên nội dung):\n",
    "1.1. Phân loại video (có thể dựa trên các từ khóa):\n",
    "- \"Ăn vặt đường phố\": từ khóa \"xe đẩy\", \"vỉa hè\", \"đồ ăn vặt\", \"chợ đêm\", \"hàng rong\", \"đường phố\" -> \"type\": 0\n",
    "- \"Nhà hàng, Quán ăn\": từ khóa \"nhà hàng\", \"quán ăn\", \"đặt bàn\", \"phục vụ\", \"buffet\", \"sang trọng\", \"bình dân\", \"quầy bar\" -> \"type\": 1\n",
    "- \"Nấu ăn\": từ khóa \"nấu ăn\", \"công thức\", \"chế biến\", \"nguyên liệu\", \"bếp\", \"tại nhà\", \"dụng cụ nấu bếp\" -> \"type\": 2\n",
    "- \"Khác\": Không thể phân loại -> \"type\": 3\n",
    "\n",
    "1.2. Xác định tất cả các món ăn được đề cập (có thể có nhiều món ăn): Lưu tất cả các món ăn vào \"food\" và trả về theo dạng string data type (str), các món ăn được cách nhau bởi dấu phẩy (\",\").\n",
    "1.3. Địa điểm: Xác định thành phố, quận/huyện tại Việt Nam\n",
    "\n",
    "Bước 2: Trả về kết quả JSON:\n",
    "{{\n",
    "    \"type\": \"Phân loại 0, 1, 2, 3\",\n",
    "    \"food\": \"Tất cả các món ăn được đề cập\",\n",
    "    \"city\": \"Thành phố\",\n",
    "    \"district\": \"Quận/Huyện\",\n",
    "    \"source\": \"transcript/desc\"\n",
    "}}\n",
    "\n",
    "Lưu Ý:\n",
    "- Ưu tiên thông tin chính xác\n",
    "- Bám sát nội dung\n",
    "- Trả về đúng định dạng JSON\n",
    "- Các thông tin trả về đều phải có đúng định dạng\n",
    "- Đối với các video không thuộc chủ đề ẩm thực thì hãy trả về None cho tất cả các trường\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Bạn là một chuyên gia trong lĩnh vực phân tích dữ liệu thông minh. Bạn có thể phân tích nội dung video và trích xuất thông tin từ đó. Người dùng sẽ cung cấp thông tin về mô tả và transcript của video TikTok về chủ đề ẩm thực. Hãy trích xuất thông tin về các món ăn và địa điểm được đề cập trong video đó. Bạn sẽ trả về một JSON chứa các thông tin sau:\n",
    "{\n",
    "    \"foods\": Danh sách các món ăn được đề cập trong video (danh sách string),\n",
    "    \"city: Tên thành phố (string),\n",
    "    \"district\": Tên quận/huyện (string)\n",
    "}\n",
    "\n",
    "Đây là một số lưu ý quan trọng:\n",
    "- Đối với các video không thuộc chủ đề ẩm thực thì hãy trả về None cho tất cả các trường\n",
    "- Các thông tin trả về đều phải có đúng định dạng\n",
    "- Trả về kết quả theo đúng định dạng JSON\n",
    "- Ưu tiên thông tin chính xác\n",
    "- Câu trả lời phải bám sát theo nội dung được cung cấp\n",
    "\n",
    "Dưới đây là mô tả và transcript của video TikTok:\n",
    "- Mô tả: %s\n",
    "- Transcript: %s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR = None\n",
    "\n",
    "\n",
    "def process_video_content(desc: str, transcript: str,\n",
    "                          api_key: str) -> str:\n",
    "    global ERROR\n",
    "    try:\n",
    "        # Call the API to generate content\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash',\n",
    "            contents=[\n",
    "                prompt % (desc, transcript),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Extract JSON content from the markdown-formatted response\n",
    "        json_text: str = response.text\n",
    "        # Remove the markdown code block formatting\n",
    "        json_text: str = re.sub(r'^```json\\n|\\n```$', '', json_text)\n",
    "\n",
    "        return json_text\n",
    "\n",
    "    except Exception as e:\n",
    "        ERROR = e\n",
    "        print(f\"[Error] API `{api_key}` failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_response(video_id: str, json_text: str) -> bool:\n",
    "    # Define the file path for the target JSON file\n",
    "    output_path: str = FOOD_LOCATION_FOLDER + f\"/{video_id}.json\"\n",
    "\n",
    "    # Save the JSON response to a file\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(json_text)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Saved response to {output_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to save response to {output_path}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đoạn chương trình chính\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bạn là một chuyên gia trong lĩnh vực phân tích dữ liệu thông minh. Bạn có thể phân tích nội dung video và trích xuất thông tin từ đó. Người dùng sẽ cung cấp thông tin về mô tả và transcript của video TikTok về chủ đề ẩm thực. Hãy trích xuất thông tin về các món ăn và địa điểm được đề cập trong video đó. Bạn sẽ trả về một JSON chứa các thông tin sau:\n",
      "{\n",
      "    \"foods\": Danh sách các món ăn được đề cập trong video (danh sách string),\n",
      "    \"city: Tên thành phố (string),\n",
      "    \"district\": Tên quận/huyện (string)\n",
      "}\n",
      "\n",
      "Đây là một số lưu ý quan trọng:\n",
      "- Đối với các video không thuộc chủ đề ẩm thực thì hãy trả về None cho tất cả các trường\n",
      "- Các thông tin trả về đều phải có đúng định dạng\n",
      "- Trả về kết quả theo đúng định dạng JSON\n",
      "- Ưu tiên thông tin chính xác\n",
      "- Câu trả lời phải bám sát theo nội dung được cung cấp\n",
      "\n",
      "Dưới đây là mô tả và transcript của video TikTok:\n",
      "- Mô tả: Say nắng trước khi được ly trà sữa 🤡 #ReviewAnNgon #vtmgr #reviewamthuc #tittungtang #LearnOnTiktok #AnCungTikTok #quan1 \n",
      "- Transcript: rồi để em xíu nha. mỗi người một một ít uống cho biết thôi nha. dạ. dạ ok trà đá còn nhiều lắm chú ơi. chờ trà đá thôi nha. trời ơi cái gì đây vậy?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View complete prompt from 1 random video\n",
    "row_idx = random.choice(video_id_range)\n",
    "video_id, desc, transcript = video_df.loc[\n",
    "    row_idx, [\"video.id\", \"desc\", \"transcript\"]]\n",
    "print(prompt % (desc, transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14252/14252 [00:00<00:00, 43022.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for row_id in tqdm(video_id_range):\n",
    "    # Extract the videoID, description, and transcript from the DataFrame\n",
    "    video_id = video_df.loc[row_id, \"video.id\"]\n",
    "    desc = video_df.loc[row_id, \"desc\"]\n",
    "    transcript = video_df.loc[row_id, \"transcript\"]\n",
    "\n",
    "    # Skip if the video ID has already been preprocessed\n",
    "    if video_id in preprocessed_video_ids:\n",
    "        # print(f\"Row {row_id} => Already preprocessed\")\n",
    "        continue\n",
    "\n",
    "    # ========================================================\n",
    "    # ********** MUST STOP IF API QUOTA IS EXCEEDED **********\n",
    "    # ========================================================\n",
    "    # Process the audio to generate the transcript\n",
    "    json_text = process_video_content(\n",
    "        desc=desc, transcript=transcript, api_key=api_list[api_idx])\n",
    "\n",
    "    # Increment the number of consecutive requests\n",
    "    n_consecutive_requests += 1\n",
    "    # Check if the number of consecutive requests exceeds the threshold\n",
    "    # and change the API key if necessary\n",
    "    if n_consecutive_requests >= api_request_threshold:\n",
    "        n_consecutive_requests = 0\n",
    "        api_idx = (api_idx + 1) % n_apis\n",
    "        print(f\"Row {row_id} => Change API key\")\n",
    "\n",
    "    # # Sleep for a while to avoid hitting the API rate limit\n",
    "    # time.sleep(1)\n",
    "\n",
    "    if not json_text:\n",
    "        print(f\"Error processing content for the row: {row_id}\")\n",
    "        # break\n",
    "\n",
    "        sec = 15\n",
    "        print(f\">> Sleeping for {sec} seconds before retrying...\")\n",
    "        time.sleep(sec)\n",
    "        n_consecutive_requests += 8\n",
    "\n",
    "        # # Change the API key\n",
    "        # api_idx = (api_idx + 1) % n_apis\n",
    "        # n_consecutive_requests = 0\n",
    "        # print(f\"Row {row_id} => Change API key\")\n",
    "        continue\n",
    "\n",
    "    # Save the transcript to a JSON file\n",
    "    if not save_response(video_id, json_text):\n",
    "        print(f\"Error saving response for video ID: {video_id}\")\n",
    "        break\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tìm ra các file JSON trong thư mục\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "\n",
    "def list_file_types(directory: str, file_extension: str) -> List[str]:\n",
    "    \"\"\" List all files with a specific extension in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory path.\n",
    "        file_extension (str): File extension.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    file_list: List[str] = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(file_extension):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of JSON files found: 14252\n"
     ]
    }
   ],
   "source": [
    "json_files = list_file_types(\"food_location\", \".json\")\n",
    "print(f\"Number of JSON files found: {len(json_files)}\")\n",
    "# print(json_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14252/14252 [00:00<00:00, 763516.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set of filenames\n",
    "file_names = set()\n",
    "\n",
    "# Get a list of JSON files\n",
    "for json_file in tqdm(json_files):\n",
    "    # Extract base name of the file\n",
    "    # remove file extension\n",
    "    file_name = os.path.basename(json_file).replace(\".json\", \"\")\n",
    "    # print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    # Append to the set\n",
    "    file_names.add(file_name)\n",
    "\n",
    "assert len(file_names) == len(json_files), \"Duplicate file names found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the set of filenames to a text file\n",
    "with open(\"preprocessed_video_ids.txt\", \"w\") as f:\n",
    "    for file_name in file_names:\n",
    "        f.write(f\"{file_name}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
