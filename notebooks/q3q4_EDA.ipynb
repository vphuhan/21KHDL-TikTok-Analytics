{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import chardet\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "# plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_columns(df):\n",
    "    \"\"\"Validate and handle required columns\"\"\"\n",
    "    required_columns = {\n",
    "        'desc': str,\n",
    "        'stats.playCount': float,\n",
    "        'stats.diggCount': float,\n",
    "        'stats.shareCount': float,\n",
    "        'stats.commentCount': float,\n",
    "        'video.duration': float\n",
    "    }\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Warning: Missing columns: {missing_columns}\")\n",
    "        for col in missing_columns:\n",
    "            df[col] = required_columns[col]()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path, sample_size=10000):\n",
    "    \"\"\"Detect file encoding using chardet\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read(sample_size)\n",
    "    return chardet.detect(raw_data)['encoding']\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Load and preprocess the TikTok data with robust error handling\"\"\"\n",
    "    try:\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "            return None\n",
    "\n",
    "        # Detect encoding dynamically\n",
    "        detected_encoding = detect_encoding(file_path)\n",
    "        print(f\"Detected encoding: {detected_encoding}\")\n",
    "\n",
    "        # Load with detected encoding\n",
    "        df = pd.read_csv(file_path, sep='\\t', encoding=detected_encoding, on_bad_lines='skip')\n",
    "        print(\"Successfully loaded data!\")\n",
    "\n",
    "        # Validate required columns\n",
    "        df = validate_columns(df)\n",
    "\n",
    "        # Data preprocessing\n",
    "        df['desc'] = df['desc'].fillna('')\n",
    "        df['clean_desc'] = df['desc'].apply(lambda x: re.sub(r'[^\\w\\s#]', '', str(x).lower()))\n",
    "        df['hashtags'] = df['desc'].apply(lambda x: re.findall(r'#(\\w+)', str(x).lower()))\n",
    "        df['hashtag_count'] = df['hashtags'].apply(len)\n",
    "\n",
    "        # Convert numeric columns\n",
    "        numeric_columns = ['stats.playCount', 'stats.diggCount', 'stats.shareCount', \n",
    "                           'stats.commentCount', 'video.duration']\n",
    "        for col in numeric_columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_video_metrics_distribution(df):\n",
    "    \"\"\"Analyze distribution of key video metrics with outlier handling\"\"\"\n",
    "    metrics = ['stats.playCount', 'stats.diggCount', 'stats.shareCount', 'stats.commentCount']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Distribution of Video Metrics (Excluding Outliers)', fontsize=16)\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i//2, i%2]\n",
    "        \n",
    "        # Remove extreme outliers for visualization\n",
    "        q1 = df[metric].quantile(0.25)\n",
    "        q3 = df[metric].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        \n",
    "        # Plot histogram and KDE\n",
    "        sns.histplot(data=df[df[metric] <= upper_bound], x=metric, ax=ax, bins=30, kde=True)\n",
    "        \n",
    "        ax.set_title(f'{metric.split(\".\")[-1]} Distribution')\n",
    "        ax.set_xlabel(metric.split('.')[-1])\n",
    "        ax.set_ylabel('Count')\n",
    "        \n",
    "        # Add statistics\n",
    "        stats = df[metric].describe()\n",
    "        stats_text = (f'Mean: {stats[\"mean\"]:,.0f}\\n'\n",
    "                     f'Median: {stats[\"50%\"]:,.0f}\\n'\n",
    "                     f'Max: {stats[\"max\"]:,.0f}\\n'\n",
    "                     f'% Outliers: {(df[metric] > upper_bound).mean()*100:.1f}%')\n",
    "        \n",
    "        ax.text(0.95, 0.95, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_engagement_patterns(df):\n",
    "    \"\"\"Analyze engagement patterns and correlations\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Engagement rate distribution\n",
    "    sns.histplot(data=df[df['engagement_rate'] <= df['engagement_rate'].quantile(0.95)],\n",
    "                x='engagement_rate', bins=30, ax=ax1, kde=True)\n",
    "    ax1.set_title('Distribution of Engagement Rates (Excluding Top 5%)')\n",
    "    ax1.set_xlabel('Engagement Rate')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # Add engagement statistics\n",
    "    stats = df['engagement_rate'].describe()\n",
    "    stats_text = (f'Mean: {stats[\"mean\"]:.3f}\\n'\n",
    "                 f'Median: {stats[\"50%\"]:.3f}\\n'\n",
    "                 f'95th percentile: {stats[\"95%\"]:.3f}')\n",
    "    ax1.text(0.95, 0.95, stats_text,\n",
    "             transform=ax1.transAxes,\n",
    "             verticalalignment='top',\n",
    "             horizontalalignment='right',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Correlation matrix\n",
    "    metrics = ['stats.playCount', 'stats.diggCount', 'stats.shareCount', \n",
    "              'stats.commentCount', 'hashtag_count', 'duration_min']\n",
    "    corr = df[metrics].corr()\n",
    "    \n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, ax=ax2, fmt='.2f')\n",
    "    ax2.set_title('Correlation Between Video Metrics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_hashtags_and_duration(df):\n",
    "    \"\"\"Analyze hashtag usage and video duration patterns\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Hashtag count distribution\n",
    "    sns.histplot(data=df, x='hashtag_count', bins=range(0, df['hashtag_count'].max()+2),\n",
    "                ax=ax1, discrete=True)\n",
    "    ax1.set_title('Distribution of Hashtags per Video')\n",
    "    ax1.set_xlabel('Number of Hashtags')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # Top hashtags\n",
    "    all_hashtags = [tag for tags in df['hashtags'] for tag in tags]\n",
    "    top_hashtags = pd.Series(all_hashtags).value_counts().head(10)\n",
    "    \n",
    "    sns.barplot(x=top_hashtags.values, y=top_hashtags.index, ax=ax2)\n",
    "    ax2.set_title('Top 10 Most Used Hashtags')\n",
    "    ax2.set_xlabel('Count')\n",
    "    \n",
    "    # Video duration distribution\n",
    "    sns.histplot(data=df[df['duration_min'] <= df['duration_min'].quantile(0.95)],\n",
    "                x='duration_min', bins=30, ax=ax3, kde=True)\n",
    "    ax3.set_title('Video Duration Distribution (Excluding Top 5%)')\n",
    "    ax3.set_xlabel('Duration (minutes)')\n",
    "    ax3.set_ylabel('Count')\n",
    "    \n",
    "    # Duration vs engagement\n",
    "    sns.scatterplot(data=df[df['duration_min'] <= df['duration_min'].quantile(0.95)],\n",
    "                    x='duration_min', y='engagement_rate', ax=ax4, alpha=0.5)\n",
    "    ax4.set_title('Duration vs Engagement Rate')\n",
    "    ax4.set_xlabel('Duration (minutes)')\n",
    "    ax4.set_ylabel('Engagement Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_wordcloud(df):\n",
    "    \"\"\"Create word cloud from video descriptions\"\"\"\n",
    "    text = ' '.join(df['clean_desc'])\n",
    "    wordcloud = WordCloud(width=1200, height=600,\n",
    "                         background_color='white',\n",
    "                         max_words=200,\n",
    "                         collocations=False).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Video Descriptions', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    default_path = \"C:/Users/nguye/OneDrive/Tài liệu/GitHub/21KHDL-TikTok-Analytics/data/interim/video_info.csv\"\n",
    "   \n",
    "    file_path = os.getenv('TIKTOK_DATA_PATH', default_path)\n",
    "    \n",
    "    print(f\"Attempting to load data from: {file_path}\")\n",
    "    \n",
    "    df = load_and_preprocess_data(file_path)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nSuccessfully loaded {len(df)} records\")\n",
    "    \n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(df[['stats.playCount', 'stats.diggCount', 'stats.shareCount', \n",
    "              'stats.commentCount', 'engagement_rate', 'duration_min']].describe())\n",
    "    \n",
    "    # Generate visualizations\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    plot_video_metrics_distribution(df)\n",
    "    analyze_engagement_patterns(df)\n",
    "    analyze_hashtags_and_duration(df)\n",
    "    create_wordcloud(df)\n",
    "    \n",
    "    # Save processed data\n",
    "    try:\n",
    "        output_path = Path('processed_tiktok_data.csv')\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nSaved processed data to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving processed data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute 'stdou'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m         \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdou\u001b[49m(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     default_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/nguye/OneDrive/Tài liệu/GitHub/21KHDL-TikTok-Analytics/data/interim/video_info.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIKTOK_DATA_PATH\u001b[39m\u001b[38;5;124m'\u001b[39m, default_path)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sys' has no attribute 'stdou'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedDataProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
