{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWb1yKciXdR"
      },
      "source": [
        "# Install package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4teR9kRiMGi",
        "outputId": "b1c62c7e-d805-4efe-b613-8d11ea1debcc"
      },
      "outputs": [],
      "source": [
        "# !pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIhB_GrejXKO"
      },
      "source": [
        "# Import library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FAqZFP2jjZUk"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import json\n",
        "import re\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# Create audio folder if not exists\n",
        "if not os.path.exists('../data/audio'):\n",
        "    os.makedirs('../data/audio')\n",
        "# Create transcript folder if not exists\n",
        "if not os.path.exists('../data/transcripts'):\n",
        "    os.makedirs('../data/transcripts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86dgPZG1jeEo"
      },
      "source": [
        "# Các hàm tiện ích\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = genai.Client(api_key=\"AIzaSyBYqr4g63GOBTslf5xP0-AbIcSSlAuvMnM\")\n",
        "prompt = \"\"\"\n",
        "Generate a transcript of the speech. The speech is in Vietnamese. If there is no speech in the file, return None.\n",
        "Then generate 3 takeaways from the speech. The takeaways should be concise and informative, written in Vietnamese.\n",
        "Check if the speech contains calls to action (CTA) sentences.\n",
        "Check if the speech contains elements of curiosity gap.\n",
        "\n",
        "Return the results in JSON format with fields: \n",
        "{\n",
        "    \"transcript\": \"The transcript of the speech\",\n",
        "    \"takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"],\n",
        "    \"has_call_to_action\": true/false,\n",
        "    \"has_curiosity_gap\": true/false\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "prompt = \"\"\"\n",
        "Generate a transcript of the speech. The speech is in Vietnamese. \n",
        "If there is no speech in the file, return None.\n",
        "\n",
        "Then generate 3 takeaways from the speech. \n",
        "The takeaways should be concise and informative, written in Vietnamese.\n",
        "\n",
        "Check if the speech contains calls to action (CTA) sentences.\n",
        "Check if the speech contains elements of curiosity gap.\n",
        "\n",
        "Return the results in JSON format with fields: \n",
        "{\n",
        "    \"transcript\": \"The transcript of the speech\",\n",
        "    \"takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"],\n",
        "    \"has_call_to_action\": true/false,\n",
        "    \"has_curiosity_gap\": true/false\n",
        "}\n",
        "\"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wMjnyyXBjVuK"
      },
      "outputs": [],
      "source": [
        "def download_youtube_audio(url: str, video_id: str) -> str:\n",
        "    # Define the file path for the target audio file\n",
        "    output_path: str = f\"../data/audio/{video_id}.wav\"\n",
        "\n",
        "    # Check if the video is already downloaded\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio file already exists: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    # Download the audio from the YouTube video\n",
        "    print(f\"Downloading audio from YouTube: {url}\")\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }],\n",
        "        'outtmpl': output_path,\n",
        "        'keepvideo': True,\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([url])\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Check if the file was renamed to .wav.wav\n",
        "    if os.path.exists(output_path + \".wav\"):\n",
        "        os.rename(output_path + \".wav\", output_path)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio download completed. File saved at: {output_path}\")\n",
        "        print(\n",
        "            f\"File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after download.\")\n",
        "        output_path = None\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def process_audio(wav_file: str) -> str:\n",
        "    # Open the audio file and read the content\n",
        "    with open(wav_file, 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "\n",
        "    try:\n",
        "        # Call the API to generate content\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.0-flash',\n",
        "            contents=[\n",
        "                prompt,\n",
        "                types.Part.from_bytes(\n",
        "                    data=image_bytes,\n",
        "                    mime_type='audio/wav',\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract JSON content from the markdown-formatted response\n",
        "        json_text: str = response.text\n",
        "        # Remove the markdown code block formatting\n",
        "        json_text: str = re.sub(r'^```json\\n|\\n```$', '', json_text)\n",
        "\n",
        "        return json_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing audio file {wav_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_response(video_id: str, json_text: str) -> bool:\n",
        "    # Define the file path for the target JSON file\n",
        "    output_path: str = f\"../data/transcripts/{video_id}.json\"\n",
        "\n",
        "    # Save the JSON response to a file\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(json_text)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Transcript saved to file: {output_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after saving.\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Đọc dữ liệu vào dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg9P6osLmDXk",
        "outputId": "2bc7b3a2-d319-4c18-d22c-1175203c0cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   year               1400 non-null   int64  \n",
            " 1   week               1400 non-null   int64  \n",
            " 2   weekly_score       1400 non-null   float64\n",
            " 3   weekly_score_rank  1400 non-null   float64\n",
            " 4   author.uniqueId    1400 non-null   object \n",
            " 5   video.id           1400 non-null   object \n",
            " 6   desc               1399 non-null   object \n",
            " 7   video.duration     1400 non-null   float64\n",
            " 8   hashtags           1393 non-null   object \n",
            " 9   num_hashtags       1400 non-null   int64  \n",
            " 10  engagement_rate    1400 non-null   float64\n",
            " 11  video.url          1400 non-null   object \n",
            "dtypes: float64(4), int64(3), object(5)\n",
            "memory usage: 131.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Define data types of some columns\n",
        "dtypes = {\n",
        "    \"author.uniqueId\": np.object_,\n",
        "    \"video.id\": np.object_,\n",
        "}\n",
        "\n",
        "# Load data from CSV file\n",
        "video_df = pd.read_csv(\"../data/interim/top_20_weekly_videos.csv\",\n",
        "                       dtype=dtypes)\n",
        "video_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chuẩn bị xử lý dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DSpOWm80tddk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bắt đầu từ index: 1400\n"
          ]
        }
      ],
      "source": [
        "# Calculate the number of file in transcript folder\n",
        "transcript_files = os.listdir(\"../data/transcripts\")\n",
        "start_index = len(transcript_files)\n",
        "\n",
        "# Print the start index\n",
        "print(f\"Bắt đầu từ index: {start_index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYq2eniymJ8w",
        "outputId": "21c0c906-2b49-4f1d-b714-3a4da6826efd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "for row_id in tqdm(range(video_df.shape[0])[start_index:]):\n",
        "    # Extract the video_id and url from the DataFrame\n",
        "    video_id = video_df.loc[row_id, \"video.id\"]\n",
        "    url = video_df.loc[row_id, \"video.url\"]\n",
        "\n",
        "    # Download the audio from the video\n",
        "    wav_file = download_youtube_audio(url, video_id)\n",
        "    if not wav_file:\n",
        "        print(f\"Error downloading audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Process the audio to generate the transcript\n",
        "    json_text = process_audio(wav_file)\n",
        "    if not json_text:\n",
        "        print(f\"Error processing audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Save the transcript to a JSON file\n",
        "    if not save_response(video_id, json_text):\n",
        "        print(f\"Error saving transcript for the row: {row_id}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Đọc các file JSON và chuyển thành dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tìm ra các file JSON trong thư mục"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_file_types(directory: str, file_extension: str) -> List[str]:\n",
        "    \"\"\" List all files with a specific extension in a directory.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Directory path.\n",
        "        file_extension (str): File extension.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of file paths.\n",
        "    \"\"\"\n",
        "\n",
        "    file_list: List[str] = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(file_extension):\n",
        "                file_list.append(os.path.join(root, file))\n",
        "    return file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of JSON files found: 1400\n",
            "['../data/transcripts/7305335962324749576.json', '../data/transcripts/7305366271976082689.json', '../data/transcripts/7305379124066012418.json', '../data/transcripts/7305392693235043602.json', '../data/transcripts/7305410066394418433.json']\n"
          ]
        }
      ],
      "source": [
        "json_files = list_file_types(\"../data/transcripts\", \".json\")\n",
        "print(f\"Number of JSON files found: {len(json_files)}\")\n",
        "print(json_files[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Đọc mỗi file JSON và chuyển thành dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1400/1400 [00:02<00:00, 559.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of records loaded: 1382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Read each JSON file, extract the fields, and store the data in a list\n",
        "# The data will be used to create a DataFrame\n",
        "\n",
        "# Valid data\n",
        "data: List[dict] = []\n",
        "# Files don't start with \"{\"\n",
        "files_not_start_with_curly_brace: List[str] = []\n",
        "# Files don't end with \"}\"\n",
        "files_not_end_with_curly_brace: List[str] = []\n",
        "# Files with \"no speech\"\n",
        "files_no_speech: List[str] = []\n",
        "# General errors\n",
        "error_files: List[str] = []\n",
        "\n",
        "for json_file in tqdm(json_files):\n",
        "    with open(json_file, 'r') as f:\n",
        "        # Remove redundant newlines and spaces\n",
        "        json_text: str = re.sub(r'\\n+', ' ', f.read()).strip()\n",
        "\n",
        "        # Find the first occurrence of \"{\"\n",
        "        start_index: int = json_text.find(\"{\")\n",
        "        if start_index > 0:\n",
        "            # Remove any text before the first \"{\"\n",
        "            json_text = json_text[start_index:]\n",
        "\n",
        "        # Check if the file contains \"no speech\"\n",
        "        if \"speech\" in json_text.lower():\n",
        "            # print(f\"File contains 'no speech': {json_file}\")\n",
        "            files_no_speech.append(json_file)\n",
        "            continue\n",
        "\n",
        "        # Check if the file starts with \"{\"\n",
        "        if not json_text.startswith(\"{\"):\n",
        "            # print(f\"File does not start with curly brace: {json_file}\")\n",
        "            files_not_start_with_curly_brace.append(json_file)\n",
        "            continue\n",
        "\n",
        "        # Check if the file ends with \"}\"\n",
        "        if not json_text.endswith(\"}\"):\n",
        "            # print(f\"File does not end with curly brace: {json_file}\")\n",
        "            files_not_end_with_curly_brace.append(json_file)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Load the JSON data from the file\n",
        "            json_data: dict = json.loads(json_text)\n",
        "\n",
        "            # Extract the fields from the JSON data\n",
        "            transcript: str = json_data.get(\"transcript\")\n",
        "            takeaways: List[str] = json_data.get(\"takeaways\")\n",
        "            call_to_action: bool = json_data.get(\"has_call_to_action\")\n",
        "            curiosity_gap: bool = json_data.get(\"has_curiosity_gap\")\n",
        "\n",
        "            # Append the data to the list\n",
        "            # Lowercase all the text fields\n",
        "            data.append({\n",
        "                \"video.id\": os.path.basename(json_file).replace(\".json\", \"\").strip(),\n",
        "                \"transcript\": transcript.lower().strip() if transcript else None,\n",
        "                \"takeaway_1\": takeaways[0].lower().strip() if takeaways else None,\n",
        "                \"takeaway_2\": takeaways[1].lower().strip() if takeaways else None,\n",
        "                \"takeaway_3\": takeaways[2].lower().strip() if takeaways else None,\n",
        "                \"transcript_call_to_action\": call_to_action,\n",
        "                \"transcript_curiosity_gap\": curiosity_gap,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing file {json_file}: {e}\")\n",
        "            error_files.append(json_file)\n",
        "\n",
        "# Make sure the data is loaded correctly\n",
        "print(f\"Number of records loaded: {len(data)}\")  # 1382\n",
        "assert len(data) == len(json_files) - len(error_files) - \\\n",
        "    len(files_not_start_with_curly_brace) - \\\n",
        "    len(files_not_end_with_curly_brace) - len(files_no_speech)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Đảm bảo không có file nào gặp lỗi mà ta không kiểm soát được"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, [])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assert len(error_files) == 0\n",
        "len(error_files), error_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không có giọng nói"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16,\n",
              " ['../data/transcripts/7306011728054095105.json',\n",
              "  '../data/transcripts/7311682555437255937.json',\n",
              "  '../data/transcripts/7312300971005168898.json',\n",
              "  '../data/transcripts/7317619747556756738.json',\n",
              "  '../data/transcripts/7340288820845284628.json',\n",
              "  '../data/transcripts/7344564266365766913.json',\n",
              "  '../data/transcripts/7353992822036499732.json',\n",
              "  '../data/transcripts/7381403673274092818.json',\n",
              "  '../data/transcripts/7384688271865023762.json',\n",
              "  '../data/transcripts/7417795304302464274.json',\n",
              "  '../data/transcripts/7433667657624341767.json',\n",
              "  '../data/transcripts/7450120578926775560.json',\n",
              "  '../data/transcripts/7453446204333116679.json',\n",
              "  '../data/transcripts/7457135184362622215.json',\n",
              "  '../data/transcripts/7463347575727443220.json',\n",
              "  '../data/transcripts/7464826799298546952.json'])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_no_speech), files_no_speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không bắt đầu bằng \"{\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2,\n",
              " ['../data/transcripts/7392173599135665425.json',\n",
              "  '../data/transcripts/7464831392392826133.json'])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_not_start_with_curly_brace), files_not_start_with_curly_brace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không kết thúc bằng \"}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, [])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_not_end_with_curly_brace), files_not_end_with_curly_brace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lưu id của các file gặp lỗi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "error_files = []\n",
        "for file in files_not_start_with_curly_brace:\n",
        "    error_files.append(os.path.basename(file).replace(\".json\", \"\"))\n",
        "for file in files_not_end_with_curly_brace:\n",
        "    error_files.append(os.path.basename(file).replace(\".json\", \"\"))\n",
        "\n",
        "# Save the id data to a text file\n",
        "with open(\"../data/error/error_files.txt\", 'w') as f:\n",
        "    for item in error_files:\n",
        "        f.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chuyển các file thành dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1382 entries, 0 to 1381\n",
            "Data columns (total 7 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   video.id                   1382 non-null   object\n",
            " 1   transcript                 1332 non-null   object\n",
            " 2   takeaway_1                 1297 non-null   object\n",
            " 3   takeaway_2                 1297 non-null   object\n",
            " 4   takeaway_3                 1297 non-null   object\n",
            " 5   transcript_call_to_action  1382 non-null   bool  \n",
            " 6   transcript_curiosity_gap   1382 non-null   bool  \n",
            "dtypes: bool(2), object(5)\n",
            "memory usage: 56.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Convert the list of dictionaries to a DataFrame\n",
        "transcript_df = pd.DataFrame(data)\n",
        "transcript_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge các dataframe lại với nhau dựa trên `video_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 18 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   year                       1400 non-null   int64  \n",
            " 1   week                       1400 non-null   int64  \n",
            " 2   weekly_score               1400 non-null   float64\n",
            " 3   weekly_score_rank          1400 non-null   float64\n",
            " 4   author.uniqueId            1400 non-null   object \n",
            " 5   video.id                   1400 non-null   object \n",
            " 6   desc                       1399 non-null   object \n",
            " 7   video.duration             1400 non-null   float64\n",
            " 8   hashtags                   1393 non-null   object \n",
            " 9   num_hashtags               1400 non-null   int64  \n",
            " 10  engagement_rate            1400 non-null   float64\n",
            " 11  video.url                  1400 non-null   object \n",
            " 12  transcript                 1332 non-null   object \n",
            " 13  takeaway_1                 1297 non-null   object \n",
            " 14  takeaway_2                 1297 non-null   object \n",
            " 15  takeaway_3                 1297 non-null   object \n",
            " 16  transcript_call_to_action  1382 non-null   object \n",
            " 17  transcript_curiosity_gap   1382 non-null   object \n",
            "dtypes: float64(4), int64(3), object(11)\n",
            "memory usage: 197.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Merge the transcript data with the video data\n",
        "# using left join to keep all video data\n",
        "video_transcript_df = pd.merge(\n",
        "    video_df, transcript_df, on=\"video.id\", how=\"left\")\n",
        "video_transcript_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>weekly_score</th>\n",
              "      <th>weekly_score_rank</th>\n",
              "      <th>author.uniqueId</th>\n",
              "      <th>video.id</th>\n",
              "      <th>desc</th>\n",
              "      <th>video.duration</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>engagement_rate</th>\n",
              "      <th>video.url</th>\n",
              "      <th>transcript</th>\n",
              "      <th>takeaway_1</th>\n",
              "      <th>takeaway_2</th>\n",
              "      <th>takeaway_3</th>\n",
              "      <th>transcript_call_to_action</th>\n",
              "      <th>transcript_curiosity_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>2024</td>\n",
              "      <td>47</td>\n",
              "      <td>24.350258</td>\n",
              "      <td>12.0</td>\n",
              "      <td>ancathegioi321</td>\n",
              "      <td>7438575079010602257</td>\n",
              "      <td>Lại thèm hàu rồi #mukbang #mukbangvideo #mukba...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>mukbang,mukbangvideo,mukbangeatingshow</td>\n",
              "      <td>3</td>\n",
              "      <td>0.024280</td>\n",
              "      <td>https://www.tiktok.com/@ancathegioi321/video/7...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>2025</td>\n",
              "      <td>6</td>\n",
              "      <td>75.287849</td>\n",
              "      <td>1.0</td>\n",
              "      <td>bon.tq1</td>\n",
              "      <td>7468628859911539969</td>\n",
              "      <td>Tết xong rồi nay chuyển qua series cơm nhà nhe...</td>\n",
              "      <td>252.0</td>\n",
              "      <td>ancungtiktok,learnontiktok,anngonnaugon,tranqu...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.034641</td>\n",
              "      <td>https://www.tiktok.com/@bon.tq1/video/74686288...</td>\n",
              "      <td>sườn non mua về mấy chị đừng có đi ra bình thư...</td>\n",
              "      <td>món sườn non rim khóm dễ làm, ai cũng có thể n...</td>\n",
              "      <td>sườn nên được trụng sơ và ướp gia vị kỹ trước ...</td>\n",
              "      <td>nêm nếm nước sốt theo khẩu vị cá nhân để món ă...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>2025</td>\n",
              "      <td>3</td>\n",
              "      <td>33.287207</td>\n",
              "      <td>9.0</td>\n",
              "      <td>phongvnguyntrn</td>\n",
              "      <td>7459246331064896786</td>\n",
              "      <td>Tính ra ăn ăn cái combo này hợp lý ghê, có cả ...</td>\n",
              "      <td>76.0</td>\n",
              "      <td>phongvureview,dcgr,reviewanngon,ancungtiktok,l...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.029233</td>\n",
              "      <td>https://www.tiktok.com/@phongvnguyntrn/video/7...</td>\n",
              "      <td>ngày anh cứ bán khoảng tầm 4 500 con là chuyện...</td>\n",
              "      <td>gà nướng chum giòn ngon, được nướng trong chum...</td>\n",
              "      <td>combo gà bao gồm gà nướng, nộm chân gà hoa chu...</td>\n",
              "      <td>quán rộng rãi, sạch sẽ, phục vụ tốt, có bán cả...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>2024</td>\n",
              "      <td>24</td>\n",
              "      <td>30.332130</td>\n",
              "      <td>18.0</td>\n",
              "      <td>ancungmaimai</td>\n",
              "      <td>7379267420579499271</td>\n",
              "      <td>Lại là tớ đây. Mời mọi người ăn viên hải sản s...</td>\n",
              "      <td>158.0</td>\n",
              "      <td>ancungmaimai,ancungtiktok,fyp,eating,mukbang,p...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.087441</td>\n",
              "      <td>https://www.tiktok.com/@ancungmaimai/video/737...</td>\n",
              "      <td>mời mọi người ăn viên hải sản sốt phô mai cùng...</td>\n",
              "      <td>giới thiệu món viên hải sản sốt phô mai chiên.</td>\n",
              "      <td>món ăn có lớp vỏ giòn và nhân phô mai.</td>\n",
              "      <td>mời mọi người cùng thưởng thức món ăn và hẹn g...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>2024</td>\n",
              "      <td>8</td>\n",
              "      <td>66.052829</td>\n",
              "      <td>2.0</td>\n",
              "      <td>chiecbungmo97</td>\n",
              "      <td>7339020465945595137</td>\n",
              "      <td>Seri mỗi ngày một món nước. TRÀ TẮC #chiecbung...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>chiecbungmo97,eating,eatingshow,mukbang,mukban...</td>\n",
              "      <td>17</td>\n",
              "      <td>0.031221</td>\n",
              "      <td>https://www.tiktok.com/@chiecbungmo97/video/73...</td>\n",
              "      <td>em và em đang cười tươi thì coi như là em đã đ...</td>\n",
              "      <td>bài hát tạo không khí vui vẻ, sôi động.</td>\n",
              "      <td>sử dụng các hiệu ứng âm thanh điện tử.</td>\n",
              "      <td>lời bài hát đơn giản, dễ nhớ.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  week  weekly_score  weekly_score_rank author.uniqueId  \\\n",
              "1051  2024    47     24.350258               12.0  ancathegioi321   \n",
              "1260  2025     6     75.287849                1.0         bon.tq1   \n",
              "1208  2025     3     33.287207                9.0  phongvnguyntrn   \n",
              "597   2024    24     30.332130               18.0    ancungmaimai   \n",
              "261   2024     8     66.052829                2.0   chiecbungmo97   \n",
              "\n",
              "                 video.id                                               desc  \\\n",
              "1051  7438575079010602257  Lại thèm hàu rồi #mukbang #mukbangvideo #mukba...   \n",
              "1260  7468628859911539969  Tết xong rồi nay chuyển qua series cơm nhà nhe...   \n",
              "1208  7459246331064896786  Tính ra ăn ăn cái combo này hợp lý ghê, có cả ...   \n",
              "597   7379267420579499271  Lại là tớ đây. Mời mọi người ăn viên hải sản s...   \n",
              "261   7339020465945595137  Seri mỗi ngày một món nước. TRÀ TẮC #chiecbung...   \n",
              "\n",
              "      video.duration                                           hashtags  \\\n",
              "1051            13.0             mukbang,mukbangvideo,mukbangeatingshow   \n",
              "1260           252.0  ancungtiktok,learnontiktok,anngonnaugon,tranqu...   \n",
              "1208            76.0  phongvureview,dcgr,reviewanngon,ancungtiktok,l...   \n",
              "597            158.0  ancungmaimai,ancungtiktok,fyp,eating,mukbang,p...   \n",
              "261             28.0  chiecbungmo97,eating,eatingshow,mukbang,mukban...   \n",
              "\n",
              "      num_hashtags  engagement_rate  \\\n",
              "1051             3         0.024280   \n",
              "1260             4         0.034641   \n",
              "1208             6         0.029233   \n",
              "597              6         0.087441   \n",
              "261             17         0.031221   \n",
              "\n",
              "                                              video.url  \\\n",
              "1051  https://www.tiktok.com/@ancathegioi321/video/7...   \n",
              "1260  https://www.tiktok.com/@bon.tq1/video/74686288...   \n",
              "1208  https://www.tiktok.com/@phongvnguyntrn/video/7...   \n",
              "597   https://www.tiktok.com/@ancungmaimai/video/737...   \n",
              "261   https://www.tiktok.com/@chiecbungmo97/video/73...   \n",
              "\n",
              "                                             transcript  \\\n",
              "1051                                               None   \n",
              "1260  sườn non mua về mấy chị đừng có đi ra bình thư...   \n",
              "1208  ngày anh cứ bán khoảng tầm 4 500 con là chuyện...   \n",
              "597   mời mọi người ăn viên hải sản sốt phô mai cùng...   \n",
              "261   em và em đang cười tươi thì coi như là em đã đ...   \n",
              "\n",
              "                                             takeaway_1  \\\n",
              "1051                                               None   \n",
              "1260  món sườn non rim khóm dễ làm, ai cũng có thể n...   \n",
              "1208  gà nướng chum giòn ngon, được nướng trong chum...   \n",
              "597      giới thiệu món viên hải sản sốt phô mai chiên.   \n",
              "261             bài hát tạo không khí vui vẻ, sôi động.   \n",
              "\n",
              "                                             takeaway_2  \\\n",
              "1051                                               None   \n",
              "1260  sườn nên được trụng sơ và ướp gia vị kỹ trước ...   \n",
              "1208  combo gà bao gồm gà nướng, nộm chân gà hoa chu...   \n",
              "597              món ăn có lớp vỏ giòn và nhân phô mai.   \n",
              "261              sử dụng các hiệu ứng âm thanh điện tử.   \n",
              "\n",
              "                                             takeaway_3  \\\n",
              "1051                                               None   \n",
              "1260  nêm nếm nước sốt theo khẩu vị cá nhân để món ă...   \n",
              "1208  quán rộng rãi, sạch sẽ, phục vụ tốt, có bán cả...   \n",
              "597   mời mọi người cùng thưởng thức món ăn và hẹn g...   \n",
              "261                       lời bài hát đơn giản, dễ nhớ.   \n",
              "\n",
              "     transcript_call_to_action transcript_curiosity_gap  \n",
              "1051                     False                    False  \n",
              "1260                      True                     True  \n",
              "1208                      True                     True  \n",
              "597                      False                     True  \n",
              "261                      False                    False  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_transcript_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lưu dataframe cuối cùng thành file CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the merged data to a CSV file\n",
        "video_transcript_df.to_csv(\n",
        "    \"../data/interim/weekly_videos_with_transcripts.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
