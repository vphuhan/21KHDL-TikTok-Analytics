{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWb1yKciXdR"
      },
      "source": [
        "# Install package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4teR9kRiMGi",
        "outputId": "b1c62c7e-d805-4efe-b613-8d11ea1debcc"
      },
      "outputs": [],
      "source": [
        "# !pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIhB_GrejXKO"
      },
      "source": [
        "# Import library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FAqZFP2jjZUk"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import json\n",
        "import re\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# Create audio folder if not exists\n",
        "if not os.path.exists('../data/audio'):\n",
        "    os.makedirs('../data/audio')\n",
        "# Create transcript folder if not exists\n",
        "if not os.path.exists('../data/transcripts'):\n",
        "    os.makedirs('../data/transcripts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86dgPZG1jeEo"
      },
      "source": [
        "# Các hàm tiện ích\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = genai.Client(api_key=\"AIzaSyBYqr4g63GOBTslf5xP0-AbIcSSlAuvMnM\")\n",
        "prompt = \"\"\"\n",
        "Generate a transcript of the speech. The speech is in Vietnamese. If there is no speech in the file, return None.\n",
        "Then generate 3 takeaways from the speech. The takeaways should be concise and informative, written in Vietnamese.\n",
        "Check if the speech contains calls to action (CTA) sentences.\n",
        "Check if the speech contains elements of curiosity gap.\n",
        "\n",
        "Return the results in JSON format with fields: \n",
        "{\n",
        "    \"transcript\": \"The transcript of the speech\",\n",
        "    \"takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"],\n",
        "    \"has_call_to_action\": true/false,\n",
        "    \"has_curiosity_gap\": true/false\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "prompt = \"\"\"\n",
        "Generate a transcript of the speech. The speech is in Vietnamese. \n",
        "If there is no speech in the file, return None.\n",
        "\n",
        "Then generate 3 takeaways from the speech. \n",
        "The takeaways should be concise and informative, written in Vietnamese.\n",
        "\n",
        "Check if the speech contains calls to action (CTA) sentences.\n",
        "Check if the speech contains elements of curiosity gap.\n",
        "\n",
        "Return the results in JSON format with fields: \n",
        "{\n",
        "    \"transcript\": \"The transcript of the speech\",\n",
        "    \"takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"],\n",
        "    \"has_call_to_action\": true/false,\n",
        "    \"has_curiosity_gap\": true/false\n",
        "}\n",
        "\"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wMjnyyXBjVuK"
      },
      "outputs": [],
      "source": [
        "def download_youtube_audio(url: str, video_id: str) -> str:\n",
        "    # Define the file path for the target audio file\n",
        "    output_path: str = f\"../data/audio/{video_id}.wav\"\n",
        "\n",
        "    # Check if the video is already downloaded\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio file already exists: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    # Download the audio from the YouTube video\n",
        "    print(f\"Downloading audio from YouTube: {url}\")\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }],\n",
        "        'outtmpl': output_path,\n",
        "        'keepvideo': True,\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([url])\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Check if the file was renamed to .wav.wav\n",
        "    if os.path.exists(output_path + \".wav\"):\n",
        "        os.rename(output_path + \".wav\", output_path)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio download completed. File saved at: {output_path}\")\n",
        "        print(\n",
        "            f\"File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after download.\")\n",
        "        output_path = None\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def process_audio(wav_file: str) -> str:\n",
        "    # Open the audio file and read the content\n",
        "    with open(wav_file, 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "\n",
        "    try:\n",
        "        # Call the API to generate content\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.0-flash',\n",
        "            contents=[\n",
        "                prompt,\n",
        "                types.Part.from_bytes(\n",
        "                    data=image_bytes,\n",
        "                    mime_type='audio/wav',\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract JSON content from the markdown-formatted response\n",
        "        json_text: str = response.text\n",
        "        # Remove the markdown code block formatting\n",
        "        json_text: str = re.sub(r'^```json\\n|\\n```$', '', json_text)\n",
        "\n",
        "        return json_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing audio file {wav_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_response(video_id: str, json_text: str) -> bool:\n",
        "    # Define the file path for the target JSON file\n",
        "    output_path: str = f\"../data/transcripts/{video_id}.json\"\n",
        "\n",
        "    # Save the JSON response to a file\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(json_text)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Transcript saved to file: {output_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after saving.\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Đọc dữ liệu vào dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg9P6osLmDXk",
        "outputId": "2bc7b3a2-d319-4c18-d22c-1175203c0cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   year               1400 non-null   int64  \n",
            " 1   week               1400 non-null   int64  \n",
            " 2   weekly_score       1400 non-null   float64\n",
            " 3   weekly_score_rank  1400 non-null   float64\n",
            " 4   author.uniqueId    1400 non-null   object \n",
            " 5   video.id           1400 non-null   object \n",
            " 6   desc               1399 non-null   object \n",
            " 7   video.duration     1400 non-null   float64\n",
            " 8   hashtags           1393 non-null   object \n",
            " 9   num_hashtags       1400 non-null   int64  \n",
            " 10  engagement_rate    1400 non-null   float64\n",
            " 11  video.url          1400 non-null   object \n",
            "dtypes: float64(4), int64(3), object(5)\n",
            "memory usage: 131.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Define data types of some columns\n",
        "dtypes = {\n",
        "    \"author.uniqueId\": np.object_,\n",
        "    \"video.id\": np.object_,\n",
        "}\n",
        "\n",
        "# Load data from CSV file\n",
        "video_df = pd.read_csv(\"../data/interim/top_20_weekly_videos.csv\",\n",
        "                       dtype=dtypes)\n",
        "video_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chuẩn bị xử lý dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DSpOWm80tddk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bắt đầu từ index: 1400\n"
          ]
        }
      ],
      "source": [
        "# Calculate the number of file in transcript folder\n",
        "transcript_files = os.listdir(\"../data/transcripts\")\n",
        "start_index = len(transcript_files)\n",
        "\n",
        "# Print the start index\n",
        "print(f\"Bắt đầu từ index: {start_index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYq2eniymJ8w",
        "outputId": "21c0c906-2b49-4f1d-b714-3a4da6826efd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "for row_id in tqdm(range(video_df.shape[0])[start_index:]):\n",
        "    # Extract the video_id and url from the DataFrame\n",
        "    video_id = video_df.loc[row_id, \"video.id\"]\n",
        "    url = video_df.loc[row_id, \"video.url\"]\n",
        "\n",
        "    # Download the audio from the video\n",
        "    wav_file = download_youtube_audio(url, video_id)\n",
        "    if not wav_file:\n",
        "        print(f\"Error downloading audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Process the audio to generate the transcript\n",
        "    json_text = process_audio(wav_file)\n",
        "    if not json_text:\n",
        "        print(f\"Error processing audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Save the transcript to a JSON file\n",
        "    if not save_response(video_id, json_text):\n",
        "        print(f\"Error saving transcript for the row: {row_id}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Đọc các file JSON và chuyển thành dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tìm ra các file JSON trong thư mục"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_file_types(directory: str, file_extension: str) -> List[str]:\n",
        "    \"\"\" List all files with a specific extension in a directory.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Directory path.\n",
        "        file_extension (str): File extension.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of file paths.\n",
        "    \"\"\"\n",
        "\n",
        "    file_list: List[str] = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(file_extension):\n",
        "                file_list.append(os.path.join(root, file))\n",
        "    return file_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of JSON files found: 13738\n",
            "['../data/transcripts/7305335962324749576.json', '../data/transcripts/7305337630361718023.json', '../data/transcripts/7305340095152786696.json', '../data/transcripts/7305340906297675026.json', '../data/transcripts/7305341470884515079.json']\n"
          ]
        }
      ],
      "source": [
        "json_files = list_file_types(\"../data/transcripts\", \".json\")\n",
        "print(f\"Number of JSON files found: {len(json_files)}\")\n",
        "print(json_files[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Đọc mỗi file JSON và chuyển thành dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13738/13738 [01:48<00:00, 126.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of records loaded: 13346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Read each JSON file, extract the fields, and store the data in a list\n",
        "# The data will be used to create a DataFrame\n",
        "\n",
        "# Valid data\n",
        "data: List[dict] = []\n",
        "# Files don't start with \"{\"\n",
        "files_not_start_with_curly_brace: List[str] = []\n",
        "# Files don't end with \"}\"\n",
        "files_not_end_with_curly_brace: List[str] = []\n",
        "# Files with \"no speech\"\n",
        "files_no_speech: List[str] = []\n",
        "# General errors\n",
        "error_files: List[str] = []\n",
        "\n",
        "for json_file in tqdm(json_files):\n",
        "    with open(json_file, 'r') as f:\n",
        "        # Remove redundant newlines and spaces\n",
        "        json_text: str = re.sub(r'\\n+', ' ', f.read()).strip()\n",
        "\n",
        "        # Find the first occurrence of \"{\"\n",
        "        start_index: int = json_text.find(\"{\")\n",
        "        if start_index > 0:\n",
        "            # Remove any text before the first \"{\"\n",
        "            json_text = json_text[start_index:]\n",
        "\n",
        "        # Check if the file contains \"no speech\"\n",
        "        if \"speech\" in json_text.lower():\n",
        "            # print(f\"File contains 'no speech': {json_file}\")\n",
        "            files_no_speech.append(json_file)\n",
        "            continue\n",
        "\n",
        "        # Check if the file starts with \"{\"\n",
        "        if not json_text.startswith(\"{\"):\n",
        "            # print(f\"File does not start with curly brace: {json_file}\")\n",
        "            files_not_start_with_curly_brace.append(json_file)\n",
        "            continue\n",
        "\n",
        "        # Check if the file ends with \"}\"\n",
        "        if not json_text.endswith(\"}\"):\n",
        "            # print(f\"File does not end with curly brace: {json_file}\")\n",
        "            files_not_end_with_curly_brace.append(json_file)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Load the JSON data from the file\n",
        "            json_data: dict = json.loads(json_text)\n",
        "\n",
        "            # Extract the fields from the JSON data\n",
        "            transcript: str = json_data.get(\"transcript\")\n",
        "            takeaways: List[str] = json_data.get(\"takeaways\")\n",
        "            call_to_action: bool = json_data.get(\"has_call_to_action\")\n",
        "            curiosity_gap: bool = json_data.get(\"has_curiosity_gap\")\n",
        "\n",
        "            # Append the data to the list\n",
        "            # Lowercase all the text fields\n",
        "            data.append({\n",
        "                \"video.id\": os.path.basename(json_file).replace(\".json\", \"\").strip(),\n",
        "                \"transcript\": transcript.lower().strip() if transcript else None,\n",
        "                \"takeaway_1\": takeaways[0].lower().strip() if takeaways else None,\n",
        "                \"takeaway_2\": takeaways[1].lower().strip() if takeaways else None,\n",
        "                \"takeaway_3\": takeaways[2].lower().strip() if takeaways else None,\n",
        "                \"transcript_call_to_action\": call_to_action,\n",
        "                \"transcript_curiosity_gap\": curiosity_gap,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing file {json_file}: {e}\")\n",
        "            error_files.append(json_file)\n",
        "\n",
        "# Make sure the data is loaded correctly\n",
        "print(f\"Number of records loaded: {len(data)}\")  # 1382\n",
        "assert len(data) == len(json_files) - len(error_files) - \\\n",
        "    len(files_not_start_with_curly_brace) - \\\n",
        "    len(files_not_end_with_curly_brace) - len(files_no_speech)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Đảm bảo không có file nào gặp lỗi mà ta không kiểm soát được"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22,\n",
              " ['../data/transcripts/7317822265704418568.json',\n",
              "  '../data/transcripts/7327617072853191944.json',\n",
              "  '../data/transcripts/7328004148551601416.json',\n",
              "  '../data/transcripts/7328751522936835330.json',\n",
              "  '../data/transcripts/7339810597799824648.json',\n",
              "  '../data/transcripts/7342855954473536769.json',\n",
              "  '../data/transcripts/7346926600711048450.json',\n",
              "  '../data/transcripts/7351005132278009106.json',\n",
              "  '../data/transcripts/7355354140643577104.json',\n",
              "  '../data/transcripts/7367685812185517313.json',\n",
              "  '../data/transcripts/7380656319851760903.json',\n",
              "  '../data/transcripts/7383628597300382992.json',\n",
              "  '../data/transcripts/7388426518373977362.json',\n",
              "  '../data/transcripts/7394844927202446599.json',\n",
              "  '../data/transcripts/7421441000935050503.json',\n",
              "  '../data/transcripts/7428934479126744327.json',\n",
              "  '../data/transcripts/7430808778091613456.json',\n",
              "  '../data/transcripts/7442296223660264722.json',\n",
              "  '../data/transcripts/7454170454400453895.json',\n",
              "  '../data/transcripts/7455241274547817736.json',\n",
              "  '../data/transcripts/7461263958905965842.json',\n",
              "  '../data/transcripts/7474097360910454024.json'])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# assert len(error_files) == 0\n",
        "len(error_files), error_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không có giọng nói"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(227,\n",
              " ['../data/transcripts/7305786485846854920.json',\n",
              "  '../data/transcripts/7306011728054095105.json',\n",
              "  '../data/transcripts/7306526019022802183.json',\n",
              "  '../data/transcripts/7307239097892949256.json',\n",
              "  '../data/transcripts/7307592825904958728.json',\n",
              "  '../data/transcripts/7307620045776030994.json',\n",
              "  '../data/transcripts/7307931176646266113.json',\n",
              "  '../data/transcripts/7307990190323223815.json',\n",
              "  '../data/transcripts/7308213369704615175.json',\n",
              "  '../data/transcripts/7308687385108188424.json',\n",
              "  '../data/transcripts/7308963596849974535.json',\n",
              "  '../data/transcripts/7309385579295247634.json',\n",
              "  '../data/transcripts/7309737167532690696.json',\n",
              "  '../data/transcripts/7310068100093742344.json',\n",
              "  '../data/transcripts/7310982782866525441.json',\n",
              "  '../data/transcripts/7311682555437255937.json',\n",
              "  '../data/transcripts/7312073521146940690.json',\n",
              "  '../data/transcripts/7312300971005168898.json',\n",
              "  '../data/transcripts/7314262596704603393.json',\n",
              "  '../data/transcripts/7314325034636463362.json',\n",
              "  '../data/transcripts/7314633924011887873.json',\n",
              "  '../data/transcripts/7314664608231427335.json',\n",
              "  '../data/transcripts/7315003081438006529.json',\n",
              "  '../data/transcripts/7315372418690796818.json',\n",
              "  '../data/transcripts/7315645154956823816.json',\n",
              "  '../data/transcripts/7316748825882889479.json',\n",
              "  '../data/transcripts/7316777522799054088.json',\n",
              "  '../data/transcripts/7316894122290318610.json',\n",
              "  '../data/transcripts/7317545288070073602.json',\n",
              "  '../data/transcripts/7317619747556756738.json',\n",
              "  '../data/transcripts/7317869399451421970.json',\n",
              "  '../data/transcripts/7318921773204999432.json',\n",
              "  '../data/transcripts/7319095964764081415.json',\n",
              "  '../data/transcripts/7320089964367056136.json',\n",
              "  '../data/transcripts/7322074071473147143.json',\n",
              "  '../data/transcripts/7322435826712104194.json',\n",
              "  '../data/transcripts/7323218943395581185.json',\n",
              "  '../data/transcripts/7323427011664399624.json',\n",
              "  '../data/transcripts/7323920860669054215.json',\n",
              "  '../data/transcripts/7324598481413262610.json',\n",
              "  '../data/transcripts/7324911730264493320.json',\n",
              "  '../data/transcripts/7324944959923031303.json',\n",
              "  '../data/transcripts/7325022393200643335.json',\n",
              "  '../data/transcripts/7325299182087015682.json',\n",
              "  '../data/transcripts/7325646772213157138.json',\n",
              "  '../data/transcripts/7325788600476421394.json',\n",
              "  '../data/transcripts/7326469708251663624.json',\n",
              "  '../data/transcripts/7327528369954819336.json',\n",
              "  '../data/transcripts/7327632901707812103.json',\n",
              "  '../data/transcripts/7328258643177131272.json',\n",
              "  '../data/transcripts/7328304899870051591.json',\n",
              "  '../data/transcripts/7329171401347190018.json',\n",
              "  '../data/transcripts/7329831683887353090.json',\n",
              "  '../data/transcripts/7331599392895438088.json',\n",
              "  '../data/transcripts/7332079598676593928.json',\n",
              "  '../data/transcripts/7333568288414256391.json',\n",
              "  '../data/transcripts/7336073362013211922.json',\n",
              "  '../data/transcripts/7337462742690876680.json',\n",
              "  '../data/transcripts/7338664617809399042.json',\n",
              "  '../data/transcripts/7338702614135164162.json',\n",
              "  '../data/transcripts/7340288820845284628.json',\n",
              "  '../data/transcripts/7340501618917428487.json',\n",
              "  '../data/transcripts/7340870460260797714.json',\n",
              "  '../data/transcripts/7341348782572948754.json',\n",
              "  '../data/transcripts/7341709702935481608.json',\n",
              "  '../data/transcripts/7341779973012868372.json',\n",
              "  '../data/transcripts/7342087884687658247.json',\n",
              "  '../data/transcripts/7342723467948674312.json',\n",
              "  '../data/transcripts/7344564266365766913.json',\n",
              "  '../data/transcripts/7344611232105745672.json',\n",
              "  '../data/transcripts/7345116919340600584.json',\n",
              "  '../data/transcripts/7345830124387945746.json',\n",
              "  '../data/transcripts/7348801865141832961.json',\n",
              "  '../data/transcripts/7349883255086238994.json',\n",
              "  '../data/transcripts/7349899001103191303.json',\n",
              "  '../data/transcripts/7350156729759354114.json',\n",
              "  '../data/transcripts/7350330909989637378.json',\n",
              "  '../data/transcripts/7350978173397388562.json',\n",
              "  '../data/transcripts/7351321354307718402.json',\n",
              "  '../data/transcripts/7352012042569616647.json',\n",
              "  '../data/transcripts/7352360417840205072.json',\n",
              "  '../data/transcripts/7352467934687677714.json',\n",
              "  '../data/transcripts/7353992822036499732.json',\n",
              "  '../data/transcripts/7354016509049474322.json',\n",
              "  '../data/transcripts/7356497278120561927.json',\n",
              "  '../data/transcripts/7356501194610674952.json',\n",
              "  '../data/transcripts/7357650063402765575.json',\n",
              "  '../data/transcripts/7358479531386211601.json',\n",
              "  '../data/transcripts/7359171110446910738.json',\n",
              "  '../data/transcripts/7360212517118807303.json',\n",
              "  '../data/transcripts/7360617595193609479.json',\n",
              "  '../data/transcripts/7361363063821421831.json',\n",
              "  '../data/transcripts/7363277057750600967.json',\n",
              "  '../data/transcripts/7364325992388758802.json',\n",
              "  '../data/transcripts/7364794465623477512.json',\n",
              "  '../data/transcripts/7365018515201363218.json',\n",
              "  '../data/transcripts/7365733315279736072.json',\n",
              "  '../data/transcripts/7365878318857473288.json',\n",
              "  '../data/transcripts/7366192050435329287.json',\n",
              "  '../data/transcripts/7366854020285189394.json',\n",
              "  '../data/transcripts/7367720749546736903.json',\n",
              "  '../data/transcripts/7369442291590679815.json',\n",
              "  '../data/transcripts/7369960245461830930.json',\n",
              "  '../data/transcripts/7370206401118915848.json',\n",
              "  '../data/transcripts/7372016611596815634.json',\n",
              "  '../data/transcripts/7372176274791369991.json',\n",
              "  '../data/transcripts/7372580219699449121.json',\n",
              "  '../data/transcripts/7373609317888445703.json',\n",
              "  '../data/transcripts/7375168615605112071.json',\n",
              "  '../data/transcripts/7376647554286505224.json',\n",
              "  '../data/transcripts/7377316775676923143.json',\n",
              "  '../data/transcripts/7377755438953106696.json',\n",
              "  '../data/transcripts/7377755471492500737.json',\n",
              "  '../data/transcripts/7380325435957087495.json',\n",
              "  '../data/transcripts/7381403673274092818.json',\n",
              "  '../data/transcripts/7384688271865023762.json',\n",
              "  '../data/transcripts/7387253461835992328.json',\n",
              "  '../data/transcripts/7388746413313625361.json',\n",
              "  '../data/transcripts/7389209534553705735.json',\n",
              "  '../data/transcripts/7389598743063973128.json',\n",
              "  '../data/transcripts/7390596024995220754.json',\n",
              "  '../data/transcripts/7391059803612761352.json',\n",
              "  '../data/transcripts/7391448606655466759.json',\n",
              "  '../data/transcripts/7391889440454626568.json',\n",
              "  '../data/transcripts/7393237541941562632.json',\n",
              "  '../data/transcripts/7393286054465293586.json',\n",
              "  '../data/transcripts/7394051540207619335.json',\n",
              "  '../data/transcripts/7394685404458306823.json',\n",
              "  '../data/transcripts/7395222889777106177.json',\n",
              "  '../data/transcripts/7396177246181920018.json',\n",
              "  '../data/transcripts/7396211180303305992.json',\n",
              "  '../data/transcripts/7396304877258804498.json',\n",
              "  '../data/transcripts/7396532717288049927.json',\n",
              "  '../data/transcripts/7396670803665767697.json',\n",
              "  '../data/transcripts/7397006813662612754.json',\n",
              "  '../data/transcripts/7397065848940186901.json',\n",
              "  '../data/transcripts/7397387273446198546.json',\n",
              "  '../data/transcripts/7398941433044012296.json',\n",
              "  '../data/transcripts/7399258877075705106.json',\n",
              "  '../data/transcripts/7401830491730562311.json',\n",
              "  '../data/transcripts/7401836395964189970.json',\n",
              "  '../data/transcripts/7402951692745968903.json',\n",
              "  '../data/transcripts/7402982639717715218.json',\n",
              "  '../data/transcripts/7403142874579127570.json',\n",
              "  '../data/transcripts/7403642013540977928.json',\n",
              "  '../data/transcripts/7405085607329795329.json',\n",
              "  '../data/transcripts/7405095146536111367.json',\n",
              "  '../data/transcripts/7405934439861062920.json',\n",
              "  '../data/transcripts/7406995451095928082.json',\n",
              "  '../data/transcripts/7407649385053424914.json',\n",
              "  '../data/transcripts/7408914430001450247.json',\n",
              "  '../data/transcripts/7409659000343596295.json',\n",
              "  '../data/transcripts/7411461123590917383.json',\n",
              "  '../data/transcripts/7412495762807917832.json',\n",
              "  '../data/transcripts/7412643189615643911.json',\n",
              "  '../data/transcripts/7413400751881391367.json',\n",
              "  '../data/transcripts/7414697619219303688.json',\n",
              "  '../data/transcripts/7414764403821743380.json',\n",
              "  '../data/transcripts/7417303004375813384.json',\n",
              "  '../data/transcripts/7417795304302464274.json',\n",
              "  '../data/transcripts/7419308719151877384.json',\n",
              "  '../data/transcripts/7419310664583286023.json',\n",
              "  '../data/transcripts/7421785194471984392.json',\n",
              "  '../data/transcripts/7422182602506833169.json',\n",
              "  '../data/transcripts/7422612186893126920.json',\n",
              "  '../data/transcripts/7423713395322440978.json',\n",
              "  '../data/transcripts/7424350707936955656.json',\n",
              "  '../data/transcripts/7424464979346099464.json',\n",
              "  '../data/transcripts/7424477766290033927.json',\n",
              "  '../data/transcripts/7424733217179176210.json',\n",
              "  '../data/transcripts/7427103491551726866.json',\n",
              "  '../data/transcripts/7427324531271945479.json',\n",
              "  '../data/transcripts/7427477407998774536.json',\n",
              "  '../data/transcripts/7427841617559653652.json',\n",
              "  '../data/transcripts/7428956489299053832.json',\n",
              "  '../data/transcripts/7430432788219694344.json',\n",
              "  '../data/transcripts/7431548760800480513.json',\n",
              "  '../data/transcripts/7431936469708606728.json',\n",
              "  '../data/transcripts/7432604152586456327.json',\n",
              "  '../data/transcripts/7432676546315472136.json',\n",
              "  '../data/transcripts/7433404618215820545.json',\n",
              "  '../data/transcripts/7433643638996897040.json',\n",
              "  '../data/transcripts/7433667657624341767.json',\n",
              "  '../data/transcripts/7434015758901906695.json',\n",
              "  '../data/transcripts/7434382579693784327.json',\n",
              "  '../data/transcripts/7434522314324118791.json',\n",
              "  '../data/transcripts/7435125467188890898.json',\n",
              "  '../data/transcripts/7435870557813378311.json',\n",
              "  '../data/transcripts/7436212971652648200.json',\n",
              "  '../data/transcripts/7438992508593392912.json',\n",
              "  '../data/transcripts/7439352474315574535.json',\n",
              "  '../data/transcripts/7440489676177263888.json',\n",
              "  '../data/transcripts/7440788814001491201.json',\n",
              "  '../data/transcripts/7442682903839984904.json',\n",
              "  '../data/transcripts/7443379056973810952.json',\n",
              "  '../data/transcripts/7443428331711745287.json',\n",
              "  '../data/transcripts/7444030347366485255.json',\n",
              "  '../data/transcripts/7445522269683715344.json',\n",
              "  '../data/transcripts/7450120578926775560.json',\n",
              "  '../data/transcripts/7450490592116739346.json',\n",
              "  '../data/transcripts/7450849489662823688.json',\n",
              "  '../data/transcripts/7452945355089464583.json',\n",
              "  '../data/transcripts/7453446204333116679.json',\n",
              "  '../data/transcripts/7453519500198169864.json',\n",
              "  '../data/transcripts/7456047334183456008.json',\n",
              "  '../data/transcripts/7457135184362622215.json',\n",
              "  '../data/transcripts/7460393586354425106.json',\n",
              "  '../data/transcripts/7463347575727443220.json',\n",
              "  '../data/transcripts/7463707055166147857.json',\n",
              "  '../data/transcripts/7464600487434702088.json',\n",
              "  '../data/transcripts/7464826799298546952.json',\n",
              "  '../data/transcripts/7465201545978662175.json',\n",
              "  '../data/transcripts/7466460694276345106.json',\n",
              "  '../data/transcripts/7466699165381299474.json',\n",
              "  '../data/transcripts/7468913320494550279.json',\n",
              "  '../data/transcripts/7469309388591811858.json',\n",
              "  '../data/transcripts/7469767699925601543.json',\n",
              "  '../data/transcripts/7470024024328867090.json',\n",
              "  '../data/transcripts/7470532220420230418.json',\n",
              "  '../data/transcripts/7474212193383238919.json',\n",
              "  '../data/transcripts/7474509812374572296.json',\n",
              "  '../data/transcripts/7475693484448451858.json',\n",
              "  '../data/transcripts/7477605328104836359.json',\n",
              "  '../data/transcripts/7477964387572141320.json',\n",
              "  '../data/transcripts/7477967300285631752.json',\n",
              "  '../data/transcripts/7479767752610254087.json',\n",
              "  '../data/transcripts/7483108395738844423.json'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_no_speech), files_no_speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không bắt đầu bằng \"{\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(118,\n",
              " ['../data/transcripts/7307181087564893448.json',\n",
              "  '../data/transcripts/7308395723727408391.json',\n",
              "  '../data/transcripts/7309133015576268033.json',\n",
              "  '../data/transcripts/7313138182718016770.json',\n",
              "  '../data/transcripts/7313205714200071442.json',\n",
              "  '../data/transcripts/7313864443170000129.json',\n",
              "  '../data/transcripts/7313884922828164353.json',\n",
              "  '../data/transcripts/7314968733531901191.json',\n",
              "  '../data/transcripts/7315421672771702024.json',\n",
              "  '../data/transcripts/7317120189789670663.json',\n",
              "  '../data/transcripts/7319124573046312194.json',\n",
              "  '../data/transcripts/7319504418947271954.json',\n",
              "  '../data/transcripts/7321656912892660994.json',\n",
              "  '../data/transcripts/7324291698383703303.json',\n",
              "  '../data/transcripts/7324540392949484818.json',\n",
              "  '../data/transcripts/7329091466335178002.json',\n",
              "  '../data/transcripts/7330051069000699154.json',\n",
              "  '../data/transcripts/7330185685954989319.json',\n",
              "  '../data/transcripts/7332446113649167637.json',\n",
              "  '../data/transcripts/7334710515425381650.json',\n",
              "  '../data/transcripts/7336539884737301762.json',\n",
              "  '../data/transcripts/7337658088981384469.json',\n",
              "  '../data/transcripts/7339391640513088786.json',\n",
              "  '../data/transcripts/7339480804365569288.json',\n",
              "  '../data/transcripts/7340922701042765063.json',\n",
              "  '../data/transcripts/7342162164062506247.json',\n",
              "  '../data/transcripts/7342834710113996050.json',\n",
              "  '../data/transcripts/7342876859870268690.json',\n",
              "  '../data/transcripts/7344917932851383570.json',\n",
              "  '../data/transcripts/7345810444247911687.json',\n",
              "  '../data/transcripts/7346823820470127879.json',\n",
              "  '../data/transcripts/7346920812160617746.json',\n",
              "  '../data/transcripts/7346961889445940487.json',\n",
              "  '../data/transcripts/7347303306076638482.json',\n",
              "  '../data/transcripts/7349159504249916679.json',\n",
              "  '../data/transcripts/7352081087822105863.json',\n",
              "  '../data/transcripts/7352706704812870920.json',\n",
              "  '../data/transcripts/7354207382840380689.json',\n",
              "  '../data/transcripts/7355787038760783112.json',\n",
              "  '../data/transcripts/7356464060239547649.json',\n",
              "  '../data/transcripts/7356811258466667784.json',\n",
              "  '../data/transcripts/7356979327256546567.json',\n",
              "  '../data/transcripts/7357187587087387911.json',\n",
              "  '../data/transcripts/7357315697522887943.json',\n",
              "  '../data/transcripts/7357677759969234183.json',\n",
              "  '../data/transcripts/7357689464858168583.json',\n",
              "  '../data/transcripts/7360706093997100305.json',\n",
              "  '../data/transcripts/7361030332851686663.json',\n",
              "  '../data/transcripts/7361065561138171143.json',\n",
              "  '../data/transcripts/7362812129004506375.json',\n",
              "  '../data/transcripts/7363214378683976978.json',\n",
              "  '../data/transcripts/7366283544911727880.json',\n",
              "  '../data/transcripts/7366592772909894920.json',\n",
              "  '../data/transcripts/7368092281607408916.json',\n",
              "  '../data/transcripts/7368799352657071367.json',\n",
              "  '../data/transcripts/7369087704706845970.json',\n",
              "  '../data/transcripts/7369245115652590866.json',\n",
              "  '../data/transcripts/7372105218311425287.json',\n",
              "  '../data/transcripts/7373894707916573959.json',\n",
              "  '../data/transcripts/7374996748391025938.json',\n",
              "  '../data/transcripts/7375524241011182864.json',\n",
              "  '../data/transcripts/7376853529207622930.json',\n",
              "  '../data/transcripts/7377032337630022919.json',\n",
              "  '../data/transcripts/7378796953766743304.json',\n",
              "  '../data/transcripts/7378828492139400456.json',\n",
              "  '../data/transcripts/7382199247048920338.json',\n",
              "  '../data/transcripts/7387047306383674645.json',\n",
              "  '../data/transcripts/7388861929562836231.json',\n",
              "  '../data/transcripts/7390332715188407560.json',\n",
              "  '../data/transcripts/7391900613623401736.json',\n",
              "  '../data/transcripts/7392110894588742920.json',\n",
              "  '../data/transcripts/7392173599135665425.json',\n",
              "  '../data/transcripts/7393980805959208210.json',\n",
              "  '../data/transcripts/7394818625825279239.json',\n",
              "  '../data/transcripts/7398525875177786642.json',\n",
              "  '../data/transcripts/7399268542962552081.json',\n",
              "  '../data/transcripts/7401059538834656520.json',\n",
              "  '../data/transcripts/7403721702280006929.json',\n",
              "  '../data/transcripts/7404917110205418760.json',\n",
              "  '../data/transcripts/7405551953889004818.json',\n",
              "  '../data/transcripts/7405775567435468040.json',\n",
              "  '../data/transcripts/7406275935831330056.json',\n",
              "  '../data/transcripts/7406315736777411847.json',\n",
              "  '../data/transcripts/7409317101925584146.json',\n",
              "  '../data/transcripts/7411165674422226192.json',\n",
              "  '../data/transcripts/7411879305887730960.json',\n",
              "  '../data/transcripts/7413180100264414472.json',\n",
              "  '../data/transcripts/7415446267989347591.json',\n",
              "  '../data/transcripts/7415819460763831570.json',\n",
              "  '../data/transcripts/7418397636421504263.json',\n",
              "  '../data/transcripts/7418925554650320135.json',\n",
              "  '../data/transcripts/7418965598949936402.json',\n",
              "  '../data/transcripts/7420731870083550472.json',\n",
              "  '../data/transcripts/7421185110101216530.json',\n",
              "  '../data/transcripts/7422152482303872263.json',\n",
              "  '../data/transcripts/7422279975220399378.json',\n",
              "  '../data/transcripts/7423237661642591495.json',\n",
              "  '../data/transcripts/7423605393605053704.json',\n",
              "  '../data/transcripts/7425110881031163154.json',\n",
              "  '../data/transcripts/7431900663111585031.json',\n",
              "  '../data/transcripts/7432626714930449672.json',\n",
              "  '../data/transcripts/7432900508852980993.json',\n",
              "  '../data/transcripts/7437729672651214087.json',\n",
              "  '../data/transcripts/7438094957115739399.json',\n",
              "  '../data/transcripts/7440691082712714503.json',\n",
              "  '../data/transcripts/7444583502269418760.json',\n",
              "  '../data/transcripts/7444906036382731528.json',\n",
              "  '../data/transcripts/7445890502383111431.json',\n",
              "  '../data/transcripts/7450479665413770503.json',\n",
              "  '../data/transcripts/7451584155214728449.json',\n",
              "  '../data/transcripts/7451830157666454802.json',\n",
              "  '../data/transcripts/7455187352441457938.json',\n",
              "  '../data/transcripts/7461603233639992584.json',\n",
              "  '../data/transcripts/7463095079159270664.json',\n",
              "  '../data/transcripts/7464831392392826133.json',\n",
              "  '../data/transcripts/7471548025631165714.json',\n",
              "  '../data/transcripts/7478325624688463124.json',\n",
              "  '../data/transcripts/7478912821477018900.json'])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_not_start_with_curly_brace), files_not_start_with_curly_brace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Các file không kết thúc bằng \"}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25,\n",
              " ['../data/transcripts/7307971671414164743.json',\n",
              "  '../data/transcripts/7310922101316242695.json',\n",
              "  '../data/transcripts/7310933483927375111.json',\n",
              "  '../data/transcripts/7316487523872656658.json',\n",
              "  '../data/transcripts/7322072706998914312.json',\n",
              "  '../data/transcripts/7325805421325815047.json',\n",
              "  '../data/transcripts/7333628092121894152.json',\n",
              "  '../data/transcripts/7346917017733172487.json',\n",
              "  '../data/transcripts/7347547821605801234.json',\n",
              "  '../data/transcripts/7348770062393756935.json',\n",
              "  '../data/transcripts/7359212290891123986.json',\n",
              "  '../data/transcripts/7382211270017158418.json',\n",
              "  '../data/transcripts/7382913132567612689.json',\n",
              "  '../data/transcripts/7384433811246927112.json',\n",
              "  '../data/transcripts/7389476742194351380.json',\n",
              "  '../data/transcripts/7398026563486289159.json',\n",
              "  '../data/transcripts/7404846479690566930.json',\n",
              "  '../data/transcripts/7406644503412509960.json',\n",
              "  '../data/transcripts/7407806659520630034.json',\n",
              "  '../data/transcripts/7424153956684696852.json',\n",
              "  '../data/transcripts/7431131346157849863.json',\n",
              "  '../data/transcripts/7461118932275989777.json',\n",
              "  '../data/transcripts/7461959982020381959.json',\n",
              "  '../data/transcripts/7469790157047205138.json',\n",
              "  '../data/transcripts/7477941663642668296.json'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files_not_end_with_curly_brace), files_not_end_with_curly_brace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lưu id của các file gặp lỗi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "error_files = []\n",
        "for file in files_not_start_with_curly_brace:\n",
        "    error_files.append(os.path.basename(file).replace(\".json\", \"\"))\n",
        "for file in files_not_end_with_curly_brace:\n",
        "    error_files.append(os.path.basename(file).replace(\".json\", \"\"))\n",
        "\n",
        "# Save the id data to a text file\n",
        "with open(\"../data/error/error_files.txt\", 'w') as f:\n",
        "    for item in error_files:\n",
        "        f.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chuyển các file thành dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13346 entries, 0 to 13345\n",
            "Data columns (total 7 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   video.id                   13346 non-null  object\n",
            " 1   transcript                 12958 non-null  object\n",
            " 2   takeaway_1                 12630 non-null  object\n",
            " 3   takeaway_2                 12630 non-null  object\n",
            " 4   takeaway_3                 12630 non-null  object\n",
            " 5   transcript_call_to_action  13345 non-null  object\n",
            " 6   transcript_curiosity_gap   13345 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 730.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Convert the list of dictionaries to a DataFrame\n",
        "transcript_df = pd.DataFrame(data)\n",
        "transcript_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to parquet file\n",
        "transcript_df.to_parquet(\"../transcripts.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13346 entries, 0 to 13345\n",
            "Data columns (total 7 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   video.id                   13346 non-null  object\n",
            " 1   transcript                 12958 non-null  object\n",
            " 2   takeaway_1                 12630 non-null  object\n",
            " 3   takeaway_2                 12630 non-null  object\n",
            " 4   takeaway_3                 12630 non-null  object\n",
            " 5   transcript_call_to_action  13345 non-null  object\n",
            " 6   transcript_curiosity_gap   13345 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 730.0+ KB\n"
          ]
        }
      ],
      "source": [
        "new_df = pd.read_parquet(\"../transcripts.parquet\")\n",
        "new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['spicykim9386',\n",
              " 'haidangrevieww',\n",
              " 'khaikhampha',\n",
              " 'putaangi',\n",
              " 'trangtam2607',\n",
              " 'huynhanhtuan_dienvien']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_authors = None\n",
        "with open(\"../data/filters/author_unique_ids.txt\", 'r') as f:\n",
        "    filtered_authors = f.read().splitlines()\n",
        "filtered_authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70996 entries, 0 to 70995\n",
            "Data columns (total 52 columns):\n",
            " #   Column                           Non-Null Count  Dtype                           \n",
            "---  ------                           --------------  -----                           \n",
            " 0   CategoryType                     70996 non-null  object                          \n",
            " 1   author.downloadSetting           70996 non-null  object                          \n",
            " 2   author.duetSetting               70996 non-null  object                          \n",
            " 3   author.id                        70996 non-null  object                          \n",
            " 4   author.nickname                  70996 non-null  object                          \n",
            " 5   author.openFavorite              70996 non-null  bool                            \n",
            " 6   author.secUid                    70996 non-null  object                          \n",
            " 7   author.signature                 70996 non-null  object                          \n",
            " 8   author.stitchSetting             70996 non-null  object                          \n",
            " 9   author.uniqueId                  70996 non-null  object                          \n",
            " 10  author.verified                  70996 non-null  bool                            \n",
            " 11  authorStats.diggCount            70996 non-null  float64                         \n",
            " 12  authorStats.followerCount        70996 non-null  float64                         \n",
            " 13  authorStats.followingCount       70996 non-null  float64                         \n",
            " 14  authorStats.heartCount           70996 non-null  float64                         \n",
            " 15  authorStats.videoCount           70996 non-null  float64                         \n",
            " 16  createTime                       70996 non-null  datetime64[ns, Asia/Ho_Chi_Minh]\n",
            " 17  desc                             70996 non-null  object                          \n",
            " 18  diversificationId                70996 non-null  object                          \n",
            " 19  isAd                             70996 non-null  bool                            \n",
            " 20  itemCommentStatus                70996 non-null  object                          \n",
            " 21  music.authorName                 70996 non-null  object                          \n",
            " 22  music.duration                   70996 non-null  float64                         \n",
            " 23  music.id                         70996 non-null  object                          \n",
            " 24  music.isCopyrighted              70996 non-null  bool                            \n",
            " 25  music.original                   70996 non-null  bool                            \n",
            " 26  music.title                      70996 non-null  object                          \n",
            " 27  statsV2.collectCount             70996 non-null  float64                         \n",
            " 28  statsV2.commentCount             70996 non-null  float64                         \n",
            " 29  statsV2.diggCount                70996 non-null  float64                         \n",
            " 30  statsV2.playCount                70996 non-null  float64                         \n",
            " 31  statsV2.shareCount               70996 non-null  float64                         \n",
            " 32  textLanguage                     70996 non-null  object                          \n",
            " 33  textTranslatable                 70996 non-null  bool                            \n",
            " 34  video.VQScore                    70996 non-null  float64                         \n",
            " 35  video.bitrate                    70996 non-null  float64                         \n",
            " 36  video.claInfo.enableAutoCaption  70996 non-null  object                          \n",
            " 37  video.claInfo.hasOriginalAudio   70996 non-null  object                          \n",
            " 38  video.codecType                  70996 non-null  object                          \n",
            " 39  video.definition                 70996 non-null  object                          \n",
            " 40  video.duration                   70996 non-null  float64                         \n",
            " 41  video.encodedType                70996 non-null  object                          \n",
            " 42  video.height                     70996 non-null  float64                         \n",
            " 43  video.id                         70996 non-null  object                          \n",
            " 44  video.ratio                      70996 non-null  object                          \n",
            " 45  video.videoQuality               70996 non-null  object                          \n",
            " 46  video.volumeInfo.Loudness        70996 non-null  float64                         \n",
            " 47  video.volumeInfo.Peak            70996 non-null  float64                         \n",
            " 48  video.width                      70996 non-null  float64                         \n",
            " 49  collectTime                      70996 non-null  datetime64[ns, Asia/Ho_Chi_Minh]\n",
            " 50  hashtags                         70996 non-null  object                          \n",
            " 51  hashtag_count                    70996 non-null  int64                           \n",
            "dtypes: bool(6), datetime64[ns, Asia/Ho_Chi_Minh](2), float64(18), int64(1), object(25)\n",
            "memory usage: 25.3+ MB\n"
          ]
        }
      ],
      "source": [
        "full_df = pd.read_parquet(\"../preprocessed_videos.parquet\")\n",
        "full_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1335 entries, 3127 to 63020\n",
            "Data columns (total 52 columns):\n",
            " #   Column                           Non-Null Count  Dtype                           \n",
            "---  ------                           --------------  -----                           \n",
            " 0   CategoryType                     1335 non-null   object                          \n",
            " 1   author.downloadSetting           1335 non-null   object                          \n",
            " 2   author.duetSetting               1335 non-null   object                          \n",
            " 3   author.id                        1335 non-null   object                          \n",
            " 4   author.nickname                  1335 non-null   object                          \n",
            " 5   author.openFavorite              1335 non-null   bool                            \n",
            " 6   author.secUid                    1335 non-null   object                          \n",
            " 7   author.signature                 1335 non-null   object                          \n",
            " 8   author.stitchSetting             1335 non-null   object                          \n",
            " 9   author.uniqueId                  1335 non-null   object                          \n",
            " 10  author.verified                  1335 non-null   bool                            \n",
            " 11  authorStats.diggCount            1335 non-null   float64                         \n",
            " 12  authorStats.followerCount        1335 non-null   float64                         \n",
            " 13  authorStats.followingCount       1335 non-null   float64                         \n",
            " 14  authorStats.heartCount           1335 non-null   float64                         \n",
            " 15  authorStats.videoCount           1335 non-null   float64                         \n",
            " 16  createTime                       1335 non-null   datetime64[ns, Asia/Ho_Chi_Minh]\n",
            " 17  desc                             1335 non-null   object                          \n",
            " 18  diversificationId                1335 non-null   object                          \n",
            " 19  isAd                             1335 non-null   bool                            \n",
            " 20  itemCommentStatus                1335 non-null   object                          \n",
            " 21  music.authorName                 1335 non-null   object                          \n",
            " 22  music.duration                   1335 non-null   float64                         \n",
            " 23  music.id                         1335 non-null   object                          \n",
            " 24  music.isCopyrighted              1335 non-null   bool                            \n",
            " 25  music.original                   1335 non-null   bool                            \n",
            " 26  music.title                      1335 non-null   object                          \n",
            " 27  statsV2.collectCount             1335 non-null   float64                         \n",
            " 28  statsV2.commentCount             1335 non-null   float64                         \n",
            " 29  statsV2.diggCount                1335 non-null   float64                         \n",
            " 30  statsV2.playCount                1335 non-null   float64                         \n",
            " 31  statsV2.shareCount               1335 non-null   float64                         \n",
            " 32  textLanguage                     1335 non-null   object                          \n",
            " 33  textTranslatable                 1335 non-null   bool                            \n",
            " 34  video.VQScore                    1335 non-null   float64                         \n",
            " 35  video.bitrate                    1335 non-null   float64                         \n",
            " 36  video.claInfo.enableAutoCaption  1335 non-null   object                          \n",
            " 37  video.claInfo.hasOriginalAudio   1335 non-null   object                          \n",
            " 38  video.codecType                  1335 non-null   object                          \n",
            " 39  video.definition                 1335 non-null   object                          \n",
            " 40  video.duration                   1335 non-null   float64                         \n",
            " 41  video.encodedType                1335 non-null   object                          \n",
            " 42  video.height                     1335 non-null   float64                         \n",
            " 43  video.id                         1335 non-null   object                          \n",
            " 44  video.ratio                      1335 non-null   object                          \n",
            " 45  video.videoQuality               1335 non-null   object                          \n",
            " 46  video.volumeInfo.Loudness        1335 non-null   float64                         \n",
            " 47  video.volumeInfo.Peak            1335 non-null   float64                         \n",
            " 48  video.width                      1335 non-null   float64                         \n",
            " 49  collectTime                      1335 non-null   datetime64[ns, Asia/Ho_Chi_Minh]\n",
            " 50  hashtags                         1335 non-null   object                          \n",
            " 51  hashtag_count                    1335 non-null   int64                           \n",
            "dtypes: bool(6), datetime64[ns, Asia/Ho_Chi_Minh](2), float64(18), int64(1), object(25)\n",
            "memory usage: 498.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Get video.id of filtered authors\n",
        "filtered_df = full_df[full_df[\"author.uniqueId\"].isin(filtered_authors)]\n",
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_author_df = pd.merge(\n",
        "    left=filtered_df, right=transcript_df,\n",
        "    how=\"left\", left_on=\"video.id\", right_on=\"video.id\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['video.id',\n",
              " 'transcript',\n",
              " 'takeaway_1',\n",
              " 'takeaway_2',\n",
              " 'takeaway_3',\n",
              " 'transcript_call_to_action',\n",
              " 'transcript_curiosity_gap']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(transcript_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['author.uniqueId',\n",
              " 'desc',\n",
              " 'hashtags',\n",
              " 'hashtag_count',\n",
              " 'video.id',\n",
              " 'transcript',\n",
              " 'takeaway_1',\n",
              " 'takeaway_2',\n",
              " 'takeaway_3',\n",
              " 'transcript_call_to_action',\n",
              " 'transcript_curiosity_gap']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_cols = [\"author.uniqueId\", \"desc\", \"hashtags\", \"hashtag_count\"] + list(transcript_df.columns)\n",
        "selected_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1335 entries, 0 to 1334\n",
            "Data columns (total 11 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   author.uniqueId            1335 non-null   object\n",
            " 1   desc                       1335 non-null   object\n",
            " 2   hashtags                   1335 non-null   object\n",
            " 3   hashtag_count              1335 non-null   int64 \n",
            " 4   video.id                   1335 non-null   object\n",
            " 5   transcript                 1318 non-null   object\n",
            " 6   takeaway_1                 1315 non-null   object\n",
            " 7   takeaway_2                 1315 non-null   object\n",
            " 8   takeaway_3                 1315 non-null   object\n",
            " 9   transcript_call_to_action  1327 non-null   object\n",
            " 10  transcript_curiosity_gap   1327 non-null   object\n",
            "dtypes: int64(1), object(10)\n",
            "memory usage: 114.9+ KB\n"
          ]
        }
      ],
      "source": [
        "selected_cols = [\"author.uniqueId\", \"desc\", \"hashtags\", \"hashtag_count\"] + list(transcript_df.columns)\n",
        "filtered_videos_df = filtered_author_df[selected_cols]\n",
        "filtered_videos_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to parquest\n",
        "filtered_videos_df.to_parquet(\n",
        "    \"../transcript_video_6_authors.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1335 entries, 0 to 1334\n",
            "Data columns (total 11 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   author.uniqueId            1335 non-null   object\n",
            " 1   desc                       1335 non-null   object\n",
            " 2   hashtags                   1335 non-null   object\n",
            " 3   hashtag_count              1335 non-null   int64 \n",
            " 4   video.id                   1335 non-null   object\n",
            " 5   transcript                 1318 non-null   object\n",
            " 6   takeaway_1                 1315 non-null   object\n",
            " 7   takeaway_2                 1315 non-null   object\n",
            " 8   takeaway_3                 1315 non-null   object\n",
            " 9   transcript_call_to_action  1327 non-null   object\n",
            " 10  transcript_curiosity_gap   1327 non-null   object\n",
            "dtypes: int64(1), object(10)\n",
            "memory usage: 114.9+ KB\n"
          ]
        }
      ],
      "source": [
        "pd.read_parquet(\"../transcript_video_6_authors.parquet\").info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge các dataframe lại với nhau dựa trên `video_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 18 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   year                       1400 non-null   int64  \n",
            " 1   week                       1400 non-null   int64  \n",
            " 2   weekly_score               1400 non-null   float64\n",
            " 3   weekly_score_rank          1400 non-null   float64\n",
            " 4   author.uniqueId            1400 non-null   object \n",
            " 5   video.id                   1400 non-null   object \n",
            " 6   desc                       1399 non-null   object \n",
            " 7   video.duration             1400 non-null   float64\n",
            " 8   hashtags                   1393 non-null   object \n",
            " 9   num_hashtags               1400 non-null   int64  \n",
            " 10  engagement_rate            1400 non-null   float64\n",
            " 11  video.url                  1400 non-null   object \n",
            " 12  transcript                 1332 non-null   object \n",
            " 13  takeaway_1                 1297 non-null   object \n",
            " 14  takeaway_2                 1297 non-null   object \n",
            " 15  takeaway_3                 1297 non-null   object \n",
            " 16  transcript_call_to_action  1382 non-null   object \n",
            " 17  transcript_curiosity_gap   1382 non-null   object \n",
            "dtypes: float64(4), int64(3), object(11)\n",
            "memory usage: 197.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Merge the transcript data with the video data\n",
        "# using left join to keep all video data\n",
        "video_transcript_df = pd.merge(\n",
        "    video_df, transcript_df, on=\"video.id\", how=\"left\")\n",
        "video_transcript_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>week</th>\n",
              "      <th>weekly_score</th>\n",
              "      <th>weekly_score_rank</th>\n",
              "      <th>author.uniqueId</th>\n",
              "      <th>video.id</th>\n",
              "      <th>desc</th>\n",
              "      <th>video.duration</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>engagement_rate</th>\n",
              "      <th>video.url</th>\n",
              "      <th>transcript</th>\n",
              "      <th>takeaway_1</th>\n",
              "      <th>takeaway_2</th>\n",
              "      <th>takeaway_3</th>\n",
              "      <th>transcript_call_to_action</th>\n",
              "      <th>transcript_curiosity_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>2024</td>\n",
              "      <td>47</td>\n",
              "      <td>24.350258</td>\n",
              "      <td>12.0</td>\n",
              "      <td>ancathegioi321</td>\n",
              "      <td>7438575079010602257</td>\n",
              "      <td>Lại thèm hàu rồi #mukbang #mukbangvideo #mukba...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>mukbang,mukbangvideo,mukbangeatingshow</td>\n",
              "      <td>3</td>\n",
              "      <td>0.024280</td>\n",
              "      <td>https://www.tiktok.com/@ancathegioi321/video/7...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>2025</td>\n",
              "      <td>6</td>\n",
              "      <td>75.287849</td>\n",
              "      <td>1.0</td>\n",
              "      <td>bon.tq1</td>\n",
              "      <td>7468628859911539969</td>\n",
              "      <td>Tết xong rồi nay chuyển qua series cơm nhà nhe...</td>\n",
              "      <td>252.0</td>\n",
              "      <td>ancungtiktok,learnontiktok,anngonnaugon,tranqu...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.034641</td>\n",
              "      <td>https://www.tiktok.com/@bon.tq1/video/74686288...</td>\n",
              "      <td>sườn non mua về mấy chị đừng có đi ra bình thư...</td>\n",
              "      <td>món sườn non rim khóm dễ làm, ai cũng có thể n...</td>\n",
              "      <td>sườn nên được trụng sơ và ướp gia vị kỹ trước ...</td>\n",
              "      <td>nêm nếm nước sốt theo khẩu vị cá nhân để món ă...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>2025</td>\n",
              "      <td>3</td>\n",
              "      <td>33.287207</td>\n",
              "      <td>9.0</td>\n",
              "      <td>phongvnguyntrn</td>\n",
              "      <td>7459246331064896786</td>\n",
              "      <td>Tính ra ăn ăn cái combo này hợp lý ghê, có cả ...</td>\n",
              "      <td>76.0</td>\n",
              "      <td>phongvureview,dcgr,reviewanngon,ancungtiktok,l...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.029233</td>\n",
              "      <td>https://www.tiktok.com/@phongvnguyntrn/video/7...</td>\n",
              "      <td>ngày anh cứ bán khoảng tầm 4 500 con là chuyện...</td>\n",
              "      <td>gà nướng chum giòn ngon, được nướng trong chum...</td>\n",
              "      <td>combo gà bao gồm gà nướng, nộm chân gà hoa chu...</td>\n",
              "      <td>quán rộng rãi, sạch sẽ, phục vụ tốt, có bán cả...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>2024</td>\n",
              "      <td>24</td>\n",
              "      <td>30.332130</td>\n",
              "      <td>18.0</td>\n",
              "      <td>ancungmaimai</td>\n",
              "      <td>7379267420579499271</td>\n",
              "      <td>Lại là tớ đây. Mời mọi người ăn viên hải sản s...</td>\n",
              "      <td>158.0</td>\n",
              "      <td>ancungmaimai,ancungtiktok,fyp,eating,mukbang,p...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.087441</td>\n",
              "      <td>https://www.tiktok.com/@ancungmaimai/video/737...</td>\n",
              "      <td>mời mọi người ăn viên hải sản sốt phô mai cùng...</td>\n",
              "      <td>giới thiệu món viên hải sản sốt phô mai chiên.</td>\n",
              "      <td>món ăn có lớp vỏ giòn và nhân phô mai.</td>\n",
              "      <td>mời mọi người cùng thưởng thức món ăn và hẹn g...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>2024</td>\n",
              "      <td>8</td>\n",
              "      <td>66.052829</td>\n",
              "      <td>2.0</td>\n",
              "      <td>chiecbungmo97</td>\n",
              "      <td>7339020465945595137</td>\n",
              "      <td>Seri mỗi ngày một món nước. TRÀ TẮC #chiecbung...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>chiecbungmo97,eating,eatingshow,mukbang,mukban...</td>\n",
              "      <td>17</td>\n",
              "      <td>0.031221</td>\n",
              "      <td>https://www.tiktok.com/@chiecbungmo97/video/73...</td>\n",
              "      <td>em và em đang cười tươi thì coi như là em đã đ...</td>\n",
              "      <td>bài hát tạo không khí vui vẻ, sôi động.</td>\n",
              "      <td>sử dụng các hiệu ứng âm thanh điện tử.</td>\n",
              "      <td>lời bài hát đơn giản, dễ nhớ.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  week  weekly_score  weekly_score_rank author.uniqueId  \\\n",
              "1051  2024    47     24.350258               12.0  ancathegioi321   \n",
              "1260  2025     6     75.287849                1.0         bon.tq1   \n",
              "1208  2025     3     33.287207                9.0  phongvnguyntrn   \n",
              "597   2024    24     30.332130               18.0    ancungmaimai   \n",
              "261   2024     8     66.052829                2.0   chiecbungmo97   \n",
              "\n",
              "                 video.id                                               desc  \\\n",
              "1051  7438575079010602257  Lại thèm hàu rồi #mukbang #mukbangvideo #mukba...   \n",
              "1260  7468628859911539969  Tết xong rồi nay chuyển qua series cơm nhà nhe...   \n",
              "1208  7459246331064896786  Tính ra ăn ăn cái combo này hợp lý ghê, có cả ...   \n",
              "597   7379267420579499271  Lại là tớ đây. Mời mọi người ăn viên hải sản s...   \n",
              "261   7339020465945595137  Seri mỗi ngày một món nước. TRÀ TẮC #chiecbung...   \n",
              "\n",
              "      video.duration                                           hashtags  \\\n",
              "1051            13.0             mukbang,mukbangvideo,mukbangeatingshow   \n",
              "1260           252.0  ancungtiktok,learnontiktok,anngonnaugon,tranqu...   \n",
              "1208            76.0  phongvureview,dcgr,reviewanngon,ancungtiktok,l...   \n",
              "597            158.0  ancungmaimai,ancungtiktok,fyp,eating,mukbang,p...   \n",
              "261             28.0  chiecbungmo97,eating,eatingshow,mukbang,mukban...   \n",
              "\n",
              "      num_hashtags  engagement_rate  \\\n",
              "1051             3         0.024280   \n",
              "1260             4         0.034641   \n",
              "1208             6         0.029233   \n",
              "597              6         0.087441   \n",
              "261             17         0.031221   \n",
              "\n",
              "                                              video.url  \\\n",
              "1051  https://www.tiktok.com/@ancathegioi321/video/7...   \n",
              "1260  https://www.tiktok.com/@bon.tq1/video/74686288...   \n",
              "1208  https://www.tiktok.com/@phongvnguyntrn/video/7...   \n",
              "597   https://www.tiktok.com/@ancungmaimai/video/737...   \n",
              "261   https://www.tiktok.com/@chiecbungmo97/video/73...   \n",
              "\n",
              "                                             transcript  \\\n",
              "1051                                               None   \n",
              "1260  sườn non mua về mấy chị đừng có đi ra bình thư...   \n",
              "1208  ngày anh cứ bán khoảng tầm 4 500 con là chuyện...   \n",
              "597   mời mọi người ăn viên hải sản sốt phô mai cùng...   \n",
              "261   em và em đang cười tươi thì coi như là em đã đ...   \n",
              "\n",
              "                                             takeaway_1  \\\n",
              "1051                                               None   \n",
              "1260  món sườn non rim khóm dễ làm, ai cũng có thể n...   \n",
              "1208  gà nướng chum giòn ngon, được nướng trong chum...   \n",
              "597      giới thiệu món viên hải sản sốt phô mai chiên.   \n",
              "261             bài hát tạo không khí vui vẻ, sôi động.   \n",
              "\n",
              "                                             takeaway_2  \\\n",
              "1051                                               None   \n",
              "1260  sườn nên được trụng sơ và ướp gia vị kỹ trước ...   \n",
              "1208  combo gà bao gồm gà nướng, nộm chân gà hoa chu...   \n",
              "597              món ăn có lớp vỏ giòn và nhân phô mai.   \n",
              "261              sử dụng các hiệu ứng âm thanh điện tử.   \n",
              "\n",
              "                                             takeaway_3  \\\n",
              "1051                                               None   \n",
              "1260  nêm nếm nước sốt theo khẩu vị cá nhân để món ă...   \n",
              "1208  quán rộng rãi, sạch sẽ, phục vụ tốt, có bán cả...   \n",
              "597   mời mọi người cùng thưởng thức món ăn và hẹn g...   \n",
              "261                       lời bài hát đơn giản, dễ nhớ.   \n",
              "\n",
              "     transcript_call_to_action transcript_curiosity_gap  \n",
              "1051                     False                    False  \n",
              "1260                      True                     True  \n",
              "1208                      True                     True  \n",
              "597                      False                     True  \n",
              "261                      False                    False  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_transcript_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lưu dataframe cuối cùng thành file CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the merged data to a CSV file\n",
        "video_transcript_df.to_csv(\n",
        "    \"../data/interim/weekly_videos_with_transcripts.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
