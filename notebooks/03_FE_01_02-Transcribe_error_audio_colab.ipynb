{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWb1yKciXdR"
      },
      "source": [
        "# Install package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4teR9kRiMGi",
        "outputId": "f3d83ce9-c731-470b-ef16-5b266a9a721c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.2.19-py3-none-any.whl.metadata (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m153.6/171.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.2.19-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.2.19\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIhB_GrejXKO"
      },
      "source": [
        "# Import library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FAqZFP2jjZUk"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_FOLDER = \"data/audio\"\n",
        "TRANSCRIPT_FOLDER = \"data/transcripts\"\n",
        "\n",
        "# Create audio folder if not exists\n",
        "if not os.path.exists(AUDIO_FOLDER):\n",
        "    os.makedirs(AUDIO_FOLDER)\n",
        "# Create transcript folder if not exists\n",
        "if not os.path.exists(TRANSCRIPT_FOLDER):\n",
        "    os.makedirs(TRANSCRIPT_FOLDER)"
      ],
      "metadata": {
        "id": "cfCuM6kGjRDt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86dgPZG1jeEo"
      },
      "source": [
        "# Các hàm tiện ích\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KvT24TQwjAvT"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(api_key=\"AIzaSyBPAzHod49PIRQFewxCHobxSLuC43OFyTI\")\n",
        "prompt = \"\"\"\n",
        "Generate a transcript of the speech. The speech is in Vietnamese. If there is no speech in the file, return None.\n",
        "Then generate 3 takeaways from the speech. The takeaways should be concise and informative, written in Vietnamese.\n",
        "Check if the speech contains calls to action (CTA) sentences.\n",
        "Check if the speech contains elements of curiosity gap.\n",
        "\n",
        "Return the results in JSON format with fields:\n",
        "{\n",
        "    \"transcript\": \"The transcript of the speech\",\n",
        "    \"takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"],\n",
        "    \"has_call_to_action\": true/false,\n",
        "    \"has_curiosity_gap\": true/false\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wMjnyyXBjVuK"
      },
      "outputs": [],
      "source": [
        "def download_youtube_audio(url: str, video_id: str) -> str:\n",
        "    # Define the file path for the target audio file\n",
        "    output_path: str = AUDIO_FOLDER + f\"/{video_id}.wav\"\n",
        "\n",
        "    # Check if the video is already downloaded\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio file already exists: {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    # Download the audio from the YouTube video\n",
        "    print(f\"Downloading audio from YouTube: {url}\")\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }],\n",
        "        'outtmpl': output_path,\n",
        "        'keepvideo': True,\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([url])\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Check if the file was renamed to .wav.wav\n",
        "    if os.path.exists(output_path + \".wav\"):\n",
        "        os.rename(output_path + \".wav\", output_path)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Audio download completed. File saved at: {output_path}\")\n",
        "        print(\n",
        "            f\"File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after download.\")\n",
        "        output_path = None\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def process_audio(wav_file: str) -> str:\n",
        "    # Open the audio file and read the content\n",
        "    with open(wav_file, 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "\n",
        "    try:\n",
        "        # Call the API to generate content\n",
        "        response = client.models.generate_content(\n",
        "            model='gemini-2.0-flash',\n",
        "            contents=[\n",
        "                prompt,\n",
        "                types.Part.from_bytes(\n",
        "                    data=image_bytes,\n",
        "                    mime_type='audio/wav',\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Extract JSON content from the markdown-formatted response\n",
        "        json_text: str = response.text\n",
        "        # Remove the markdown code block formatting\n",
        "        json_text: str = re.sub(r'^```json\\n|\\n```$', '', json_text)\n",
        "\n",
        "        return json_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing audio file {wav_file}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_response(video_id: str, json_text: str) -> bool:\n",
        "    # Define the file path for the target JSON file\n",
        "    output_path: str = TRANSCRIPT_FOLDER + f\"/{video_id}.json\"\n",
        "\n",
        "    # Save the JSON response to a file\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(json_text)\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Transcript saved to file: {output_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Error: File {output_path} not found after saving.\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r434arMCjAvU"
      },
      "source": [
        "# Đọc dữ liệu vào dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg9P6osLmDXk",
        "outputId": "f24ec329-70c2-4572-b3b3-ac94ddc75094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400 entries, 0 to 1399\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   year               1400 non-null   int64  \n",
            " 1   week               1400 non-null   int64  \n",
            " 2   weekly_score       1400 non-null   float64\n",
            " 3   weekly_score_rank  1400 non-null   float64\n",
            " 4   author.uniqueId    1400 non-null   object \n",
            " 5   video.id           1400 non-null   object \n",
            " 6   desc               1399 non-null   object \n",
            " 7   video.duration     1400 non-null   float64\n",
            " 8   hashtags           1393 non-null   object \n",
            " 9   num_hashtags       1400 non-null   int64  \n",
            " 10  engagement_rate    1400 non-null   float64\n",
            " 11  video.url          1400 non-null   object \n",
            "dtypes: float64(4), int64(3), object(5)\n",
            "memory usage: 131.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Define data types of some columns\n",
        "dtypes = {\n",
        "    \"author.uniqueId\": np.object_,\n",
        "    \"video.id\": np.object_,\n",
        "}\n",
        "\n",
        "# Load data from CSV file\n",
        "video_df = pd.read_csv(\"top_20_weekly_videos.csv\",\n",
        "                       dtype=dtypes)\n",
        "video_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p904oKhKjAvV"
      },
      "source": [
        "# Chuẩn bị xử lý dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get set of video_id needed to transcript\n",
        "with open(\"error_files.txt\") as f:\n",
        "  video_ids = set(f.read().splitlines())\n",
        "len(video_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsxEFiRYFY-n",
        "outputId": "4255bd84-b126-4a56-bda2-aa9ee0159cf3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYq2eniymJ8w",
        "outputId": "008be3c6-548c-4db5-fc7f-cf3aa9ccaa1f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] 100% of    7.03MiB in 00:00:11 at 645.65KiB/s \n",
            "[ExtractAudio] Destination: data/audio/7391715153219177735.wav.wav\n",
            "Audio download completed. File saved at: data/audio/7391715153219177735.wav\n",
            "File size: 10.17 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [05:14<00:00, 10.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript saved to file: data/transcripts/7391715153219177735.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for video_id in tqdm(video_ids):\n",
        "    row_id = video_df[video_df[\"video.id\"] == video_id].index[0]\n",
        "\n",
        "    # Extract the video_id and url from the DataFrame\n",
        "    video_id = video_df.loc[row_id, \"video.id\"]\n",
        "    url = video_df.loc[row_id, \"video.url\"]\n",
        "\n",
        "    # Download the audio from the video\n",
        "    wav_file = download_youtube_audio(url, video_id)\n",
        "    if not wav_file:\n",
        "        print(f\"Error downloading audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Process the audio to generate the transcript\n",
        "    json_text = process_audio(wav_file)\n",
        "    if not json_text:\n",
        "        print(f\"Error processing audio for the row: {row_id}\")\n",
        "        break\n",
        "\n",
        "    # Save the transcript to a JSON file\n",
        "    if not save_response(video_id, json_text):\n",
        "        print(f\"Error saving transcript for the row: {row_id}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6HL94oMQqwfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ded1bcb-aeae-481b-ba25-fe701c7d52f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data/ (stored 0%)\n",
            "  adding: data/transcripts/ (stored 0%)\n",
            "  adding: data/transcripts/7338403909465148680.json (deflated 25%)\n",
            "  adding: data/transcripts/7376567397316103442.json (deflated 46%)\n",
            "  adding: data/transcripts/7415180429818449185.json (deflated 39%)\n",
            "  adding: data/transcripts/7460441203784518919.json (deflated 64%)\n",
            "  adding: data/transcripts/7406709590051638548.json (deflated 39%)\n",
            "  adding: data/transcripts/7380318377786543367.json (deflated 49%)\n",
            "  adding: data/transcripts/7351068138017918210.json (deflated 46%)\n",
            "  adding: data/transcripts/7376297082832833793.json (deflated 42%)\n",
            "  adding: data/transcripts/7464831392392826133.json (deflated 12%)\n",
            "  adding: data/transcripts/7404415194140658977.json (deflated 40%)\n",
            "  adding: data/transcripts/7363561574721785106.json (deflated 50%)\n",
            "  adding: data/transcripts/7391715153219177735.json (deflated 27%)\n",
            "  adding: data/transcripts/7332097613728189698.json (deflated 35%)\n",
            "  adding: data/transcripts/7330239538108910849.json (deflated 40%)\n",
            "  adding: data/transcripts/7389867785997913362.json (deflated 48%)\n",
            "  adding: data/transcripts/7389092425916239111.json (deflated 49%)\n",
            "  adding: data/transcripts/7331340645409279239.json (deflated 50%)\n",
            "  adding: data/transcripts/7340288820845284628.json (deflated 34%)\n",
            "  adding: data/transcripts/7393164094498540816.json (deflated 42%)\n",
            "  adding: data/transcripts/7314898677854702850.json (deflated 43%)\n",
            "  adding: data/transcripts/7360180740694281490.json (deflated 42%)\n",
            "  adding: data/transcripts/7444494050255801608.json (deflated 65%)\n",
            "  adding: data/transcripts/7417047329070533896.json (deflated 33%)\n",
            "  adding: data/transcripts/7393300998602771744.json (deflated 44%)\n",
            "  adding: data/transcripts/7378509552838266145.json (deflated 42%)\n",
            "  adding: data/transcripts/7355423112726400264.json (deflated 37%)\n",
            "  adding: data/transcripts/7392173599135665425.json (deflated 14%)\n",
            "  adding: data/transcripts/7443751417682169106.json (deflated 58%)\n",
            "  adding: data/transcripts/7453446204333116679.json (deflated 23%)\n",
            "  adding: data/audio/ (stored 0%)\n",
            "  adding: data/audio/7443751417682169106.wav (deflated 13%)\n",
            "  adding: data/audio/7453446204333116679.wav (deflated 9%)\n",
            "  adding: data/audio/7351068138017918210.wav (deflated 23%)\n",
            "  adding: data/audio/7415180429818449185.wav (deflated 19%)\n",
            "  adding: data/audio/7314898677854702850.wav (deflated 8%)\n",
            "  adding: data/audio/7340288820845284628.wav (deflated 17%)\n",
            "  adding: data/audio/7444494050255801608.wav (deflated 16%)\n",
            "  adding: data/audio/7376297082832833793.wav (deflated 11%)\n",
            "  adding: data/audio/7360180740694281490.wav (deflated 7%)\n",
            "  adding: data/audio/7332097613728189698.wav (deflated 21%)\n",
            "  adding: data/audio/7363561574721785106.wav (deflated 7%)\n",
            "  adding: data/audio/7380318377786543367.wav (deflated 13%)\n",
            "  adding: data/audio/7393300998602771744.wav (deflated 15%)\n",
            "  adding: data/audio/7417047329070533896.wav (deflated 16%)\n",
            "  adding: data/audio/7376567397316103442.wav (deflated 6%)\n",
            "  adding: data/audio/7464831392392826133.wav (deflated 9%)\n",
            "  adding: data/audio/7404415194140658977.wav (deflated 21%)\n",
            "  adding: data/audio/7393164094498540816.wav (deflated 7%)\n",
            "  adding: data/audio/7391715153219177735.wav (deflated 5%)\n",
            "  adding: data/audio/7331340645409279239.wav (deflated 9%)\n",
            "  adding: data/audio/7389867785997913362.wav (deflated 14%)\n",
            "  adding: data/audio/7406709590051638548.wav (deflated 5%)\n",
            "  adding: data/audio/7355423112726400264.wav (deflated 8%)\n",
            "  adding: data/audio/7460441203784518919.wav (deflated 8%)\n",
            "  adding: data/audio/7378509552838266145.wav (deflated 8%)\n",
            "  adding: data/audio/7392173599135665425.wav (deflated 10%)\n",
            "  adding: data/audio/7330239538108910849.wav (deflated 8%)\n",
            "  adding: data/audio/7338403909465148680.wav (deflated 15%)\n",
            "  adding: data/audio/7389092425916239111.wav (deflated 7%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r data.zip data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmsJP1XfkmXW",
        "outputId": "9b608193-faac-4f55-aee2-220990d87c58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  data.zip\terror_files.txt  sample_data  top_20_weekly_videos.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}