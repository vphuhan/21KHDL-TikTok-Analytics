import sys
import os

# SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# sys.path.append(os.path.dirname(SCRIPT_DIR))

try:
    import streamlit as st
    from google import genai
    import time

    import pandas as pd
    import numpy as np
    from types import NoneType

    import json
    from google import genai
    from google.genai import types


except ImportError as e:
    import traceback
    print(f"Error importing required packages: {e}")
    print(traceback.format_exc())
    try:
        # If streamlit is successfully imported, show error in UI
        if 'st' in globals():
            st.error(
                f"Failed to import required packages. Please install them using: pip install -r requirements.txt\n\nError: {e}")
            st.stop()
    except:
        # If we can't even use streamlit, exit the program
        sys.exit(1)

# App configuration
# st.set_page_config(page_title="Write Scripts", page_icon="üìù")


@st.cache_data
def load_data():
    features_df = pd.read_parquet('data/ScriptGen-data/script_gendata.parquet')

    def parse_list(x):
        if isinstance(x, np.ndarray):
            return list(x)
        if isinstance(x, NoneType):
            return []
    for col in features_df.columns:
        str_flag = features_df[col].apply(
            lambda x: isinstance(x, np.ndarray)).any()
        if str_flag:
            features_df[col] = features_df[col].apply(parse_list)
    return features_df


# st.title("Vi·∫øt k·ªãch b·∫£n video TikTok")
# st.write("[Empty for now]")

# Constants
API_KEY = "AIzaSyBaT3UMomQUPjjpbRD2pCrE_sk3nT6P47w"  # vphacc096@gmail.com
DEFAULT_MODEL = "gemini-2.0-flash"
PAGE_TITLE = "Write Scripts"
PAGE_ICON = "üìù"

# Available AI Models
AVAILABLE_MODELS = [
    "gemini-2.0-flash",         # Input: 1,048,576 tokens, Output: 8,192 tokens
    "gemini-2.0-pro-exp",       # Input: 2,048,576 tokens, Output: 8,192 tokens
    "gemini-2.0-flash-thinking-exp-1219",
    "gemini-2.0-flash-lite",    # Input: 1,048,576 tokens, Output: 8,192 tokens
    "gemini-1.5-flash",         # Input: 1,048,576 tokens, Output: 8,192 tokens
    "gemini-1.5-flash-8b",      # Input: 1,048,576 tokens, Output: 8,192 tokens
    "gemini-1.5-pro",           # Input: 2,097,152 tokens, Output: 8,192 tokens
    "learnlm-1.5-pro-experimental",
    "gemma-3-27b-it",
]


def filter_by_multiple_labels_unified(df, conditions, soft_fields=None, min_count=10):
    """
    Filter a dataframe based on initial conditions with a "relaxation" process:
    - Start with full conditions
    - Process fields in priority order: soft fields first, then strict fields
    - For each field (except 'categories'), gradually reduce labels until we have enough videos (>= min_count)
    - If still not enough, remove the field completely (except 'categories')

    Parameters:
    - df: pandas DataFrame to filter
    - conditions: dict of field -> list of labels to filter on
    - soft_fields: list of field names that can be relaxed first (default priority order)
    - min_count: minimum number of rows required in result

    Returns:
    - Filtered DataFrame with relaxed conditions if necessary
    """
    print(conditions)
    # Input validation
    if df is None or df.empty:
        print("DataFrame is empty or None")
        return df

    if conditions is None or not conditions:
        return df

    # Default soft fields if none provided
    if soft_fields is None:
        soft_fields = ["pacing", "audience_target",
                       "content_style", "tone_of_voice", "cta_type"]

    # Ensure all condition values are lists
    fixed_conditions = {k: v if isinstance(
        v, list) else [v] for k, v in conditions.items()}

    # Determine strict fields (those not in soft_fields)
    strict_fields = [f for f in fixed_conditions.keys()
                     if f not in soft_fields]

    # Processing order: soft fields first in their priority order, then strict fields
    field_order = [
        f for f in soft_fields if f in fixed_conditions] + strict_fields

    def apply_filters(dataframe, filter_conditions):
        """Apply all filter conditions to the dataframe"""
        result = dataframe.copy()
        for field, target_labels in filter_conditions.items():
            if field in result.columns and target_labels:  # Check if field exists and labels are not empty
                result = result[result[field].apply(
                    lambda labels: all(lbl in labels for lbl in target_labels))]
        return result

    # First try with all conditions
    test_conditions = fixed_conditions.copy()
    filtered_df = apply_filters(df, test_conditions)

    if len(filtered_df) >= min_count:
        print("Final condition (full):", test_conditions)
        print(filtered_df.shape)
        return filtered_df

    best_df = filtered_df  # Track the best result so far

    # Process fields in priority order
    for field in field_order:
        # Never relax 'categories' field
        if field == "categories" or field not in test_conditions:
            continue

        original_labels = test_conditions[field].copy()
        if not original_labels:  # Skip if empty list
            continue

        # Try removing labels one by one from the end
        for i in range(1, len(original_labels) + 1):
            candidate_labels = original_labels[:-i]

            # Skip if we'd end up with empty list (will be handled in the field removal step)
            if not candidate_labels:
                continue

            test_conditions[field] = candidate_labels
            filtered_df = apply_filters(df, test_conditions)

            print(
                f"Trying {field} with labels {candidate_labels}: {len(filtered_df)} results")

            if len(filtered_df) >= min_count:
                print("Final condition:", test_conditions)
                print(filtered_df.shape)
                return filtered_df

            # Keep track of best result
            if len(filtered_df) > len(best_df):
                best_df = filtered_df

        # If relaxing labels didn't help enough, try removing the field completely
        if field != "categories":
            del test_conditions[field]
            filtered_df = apply_filters(df, test_conditions)
            print(f"Removed field {field}: {len(filtered_df)} results")

            if len(filtered_df) >= min_count:
                print("Final condition:", test_conditions)
                print(filtered_df.shape)
                return filtered_df

            # Keep track of best result
            if len(filtered_df) > len(best_df):
                best_df = filtered_df

    print("Couldn't meet minimum count requirement. Returning best result with", len(
        best_df), "rows")
    print(best_df.shape)
    return best_df


def generate_labels_from_description(user_description, client, model):

    # with open('src/scriptGen/label_schema.json', 'r', encoding='utf-8') as f:
    # label_schema = json.load(f)
    label_schema = {
        "type": "object",
        "description": "C√°c tr∆∞·ªùng d√πng ƒë·ªÉ g√°n nh√£n (label). G√°n nh√£n d·ª±a tr√™n n·ªôi dung mi√™u t·∫£ video m√† ng∆∞·ªùi d√πng cung c·∫•p.",
        "required": ["categories"],
        "properties": {
            "categories": {
                "type": "string",
                "description": "Th·ªÉ lo·∫°i ch√≠nh c·ªßa video. N·∫øu k·∫øt qu·∫£ l√† 'Kh√¥ng li√™n quan ·∫©m th·ª±c' th√¨ tr·∫£ v·ªÅ duy nh·∫•t tr∆∞·ªùng 'categories', kh√¥ng c·∫ßn tr√≠ch xu·∫•t c√°c tr∆∞·ªùng kh√°c",
                "enum": [
                    "Review qu√°n ƒÉn",
                    "Review s·∫£n ph·∫©m ƒÉn u·ªëng",
                    "Review m√≥n ƒÉn",
                    "Mukbang",
                    "N·∫•u ƒÉn",
                    "Kh√¥ng li√™n quan ·∫©m th·ª±c"
                ]
            },
            "structure_style": {
                "type": "array",
                "description": "D·ª±a tr√™n c√°ch ng∆∞·ªùi d√πng mu·ªën th·ªÉ hi·ªán video, g√°n nh√£n phong c√°ch c·∫•u tr√∫c t∆∞∆°ng ·ª©ng.",
                "items": {
                    "type": "string",
                    "enum": [
                        "M√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm",
                        "Chia s·∫ª tr·∫£i nghi·ªám c√° nh√¢n",
                        "K·ªÉ chuy·ªán",
                        "H∆∞·ªõng d·∫´n",
                        "So s√°nh",
                        "K·ªãch h√≥a",
                        "ƒê·ªëi tho·∫°i",
                        "Chia s·∫ª ki·∫øn th·ª©c"
                    ]
                }
            },
            "hook_type": {
                "type": "array",
                "description": "G√°n nh√£n c√°ch m·ªü ƒë·∫ßu video m√† ng∆∞·ªùi d√πng mu·ªën s·ª≠ d·ª•ng.",
                "items": {
                    "type": "string",
                    "enum": [
                        "G√¢y t√≤ m√≤",
                        "Cho th·∫•y k·∫øt qu·∫£ tr∆∞·ªõc",
                        "K·ªÉ chuy·ªán",
                        "V√†o th·∫≥ng v·∫•n ƒë·ªÅ",
                        "ƒê·∫∑t c√¢u h·ªèi",
                        "Ph·∫£n h·ªìi b√¨nh lu·∫≠n",
                        "Khuy·∫øn m√£i",
                        "So s√°nh",
                        "Gi·∫≠t t√≠t",
                        "G√¢y tranh c√£i",
                        "T·∫°o s·ª± ƒë·ªìng c·∫£m"
                    ]
                }
            },
            "tone_of_voice": {
                "type": "array",
                "description": "X√°c ƒë·ªãnh gi·ªçng ƒëi·ªáu m√† ng∆∞·ªùi d√πng mong mu·ªën th·ªÉ hi·ªán trong video.",
                "items": {
                    "type": "string",
                    "enum": [
                        "H√†o h·ª©ng",
                        "H√†i h∆∞·ªõc",
                        "Th√¢n thi·ªán",
                        "Ch√¢n th√†nh",
                        "Ng·∫°c nhi√™n",
                        "B√≠ ·∫©n",
                        "Trung l·∫≠p",
                        "Trang tr·ªçng",
                        "Nghi√™m t√∫c",
                        "Ch√¢m bi·∫øm",
                        "Kh√≥ ch·ªãu",
                        "Gi·∫≠n d·ªØ",
                        "B·ªëc ph·ªët"
                    ]
                }
            },
            "pacing": {
                "type": "array",
                "description": "G√°n nh·ªãp ƒë·ªô video d·ª±a tr√™n c·∫£m nh·∫≠n v·ªÅ t·ªëc ƒë·ªô, kh√¥ng kh√≠ c·ªßa video m√† ng∆∞·ªùi d√πng mu·ªën t·∫°o.",
                "items": {"type": "string", "enum": ["Nhanh", "Ch·∫≠m", "Thay ƒë·ªïi"]}
            },
            "cta_type": {
                "type": "array",
                "description": "G√°n c√°c lo·∫°i CTA (k√™u g·ªçi h√†nh ƒë·ªông) m√† ng∆∞·ªùi d√πng mong mu·ªën s·ª≠ d·ª•ng trong video, n·∫øu c√≥. Ph·∫£i d·ª±a tr√™n n·ªôi dung m√¥ t·∫£ r√µ r√†ng.",
                "items": {
                    "type": "string",
                    "enum": [
                        "Follow k√™nh",
                        "Th√≠ch video",
                        "B√¨nh lu·∫≠n",
                        "Chia s·∫ª",
                        "L∆∞u video",
                        "Xem video ti·∫øp theo",
                        "Truy c·∫≠p trang c√° nh√¢n",
                        "Truy c·∫≠p link s·∫£n ph·∫©m",
                        "Th·ª≠ l√†m theo c√¥ng th·ª©c",
                        "ƒÇn c√πng",
                        "Gh√© thƒÉm ƒë·ªãa ƒëi·ªÉm",
                        "Chia s·∫ª c√¥ng th·ª©c",
                        "So s√°nh",
                        "ƒê·∫∑t c√¢u h·ªèi"
                    ]
                }
            },
            "content_style": {
                "type": "array",
                "description": "G√°n nh√£n phong c√°ch t·ªïng th·ªÉ c·ªßa video d·ª±a tr√™n phong c√°ch th·ªÉ hi·ªán m√† ng∆∞·ªùi d√πng m√¥ t·∫£.",
                "items": {
                    "type": "string",
                    "enum": [
                        "Gen Z",
                        "Truy·ªÅn th·ªëng",
                        "Chuy√™n nghi·ªáp",
                        "ƒê·ªùi th∆∞·ªùng",
                        "Sang tr·ªçng",
                        "Drama",
                        "Ki·∫øn th·ª©c",
                        "S√°ng t·∫°o",
                        "Nhanh g·ªçn",
                        "Chi ti·∫øt"
                    ]
                }
            },
            "audience_target": {
                "type": "array",
                "description": "D·ª±a tr√™n n·ªôi dung v√† c√°ch ti·∫øp c·∫≠n m√† ng∆∞·ªùi d√πng m√¥ t·∫£, x√°c ƒë·ªãnh nh√≥m kh√°n gi·∫£ m·ª•c ti√™u.",
                "items": {
                    "type": "string",
                    "enum": [
                        "H·ªçc sinh, sinh vi√™n",
                        "Ng∆∞·ªùi ƒëi l√†m, d√¢n vƒÉn ph√≤ng",
                        "Ph·ª• huynh, gia ƒë√¨nh c√≥ tr·∫ª nh·ªè",
                        "Ng∆∞·ªùi tr·∫ª (Gen Z)",
                        "Ng∆∞·ªùi n·ªôi tr·ª£, y√™u th√≠ch n·∫•u ƒÉn t·∫°i nh√†",
                        "Ng∆∞·ªùi ƒÉn chay, ƒÉn healthy",
                        "Ng∆∞·ªùi th√≠ch ƒÉn v·∫∑t, ƒë·ªì ng·ªçt",
                        "Ng∆∞·ªùi y√™u th√≠ch ·∫©m th·ª±c n∆∞·ªõc ngo√†i",
                        "Ng∆∞·ªùi th√≠ch kh√°m ph√° ·∫©m th·ª±c t·∫°i ƒë·ªãa ph∆∞∆°ng",
                        "Kh√°ch du l·ªãch, ng∆∞·ªùi Vi·ªát ·ªü n∆∞·ªõc ngo√†i"
                    ]
                }
            },
            "duration": {
                "type": "integer",
                "description": "Th·ªùi l∆∞·ª£ng mong mu·ªën c·ªßa video t√≠nh theo gi√¢y. V√≠ d·ª•: 180 (t∆∞∆°ng ƒë∆∞∆°ng 3 ph√∫t)"
            }
        }
    }

    annotate_user_desc_function = {
        "name": "filter_by_multiple_labels",
        # "description": "D·ª±a tr√™n mi√™u t·∫£ c·ªßa ng∆∞·ªùi d√πng v·ªÅ video h·ªç mu·ªën th·ª±c hi·ªán, ti·∫øn h√†nh g√°n nh√£n cho c√°c tr∆∞·ªùng ƒë∆∞·ª£c ƒë·ªãnh tr∆∞·ªõc.",
        "description": "D·ª±a tr√™n mi√™u t·∫£ c·ªßa ng∆∞·ªùi d√πng v·ªÅ video h·ªç mu·ªën th·ª±c hi·ªán, ti·∫øn h√†nh l·ªçc ra c√°c video ph√π h·ª£p v·ªõi m√¥ t·∫£ c·ªßa ng∆∞·ªùi d√πng.",
        "parameters": label_schema
    }

    system_instruction = """
    B·∫°n l√† m·ªôt h·ªá th·ªëng g√°n nh√£n n·ªôi dung video TikTok ·∫©m th·ª±c d·ª±a tr√™n m√¥ t·∫£ t·ª± do c·ªßa ng∆∞·ªùi d√πng. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t c√°c nh√£n (label) t∆∞∆°ng ·ª©ng v·ªõi schema ƒë√£ ƒë·ªãnh nghƒ©a.

    X√°c ƒë·ªãnh xem n·ªôi dung c√≥ thu·ªôc ch·ªß ƒë·ªÅ ·∫©m th·ª±c hay kh√¥ng. Ch·ªçn m·ªôt trong c√°c ch·ªß ƒë·ªÅ ·∫©m th·ª±c nh∆∞ sau:
    - Review qu√°n ƒÉn: T·∫≠p trung v√†o ƒë√°nh gi√°, gi·ªõi thi·ªáu qu√°n ƒÉn, nh√† h√†ng, xe ƒë·∫©y, ti·ªám nh·ªè,... n∆°i c√≥ th·ªÉ ƒë·∫øn ƒÉn tr·ª±c ti·∫øp.
    - Review s·∫£n ph·∫©m ƒÉn u·ªëng: ƒê√°nh gi√° c√°c lo·∫°i th·ª±c ph·∫©m ƒë√≥ng g√≥i, b√°nh k·∫πo, gia v·ªã, ƒë·ªì d√πng nh√† b·∫øp, v.v.
    - Review m√≥n ƒÉn: T·∫≠p trung v√†o ƒë√°nh gi√° h∆∞∆°ng v·ªã, ch·∫•t l∆∞·ª£ng c·ªßa m·ªôt m√≥n ƒÉn ho·∫∑c ƒë·ªì u·ªëng c·ª• th·ªÉ (c√≥ th·ªÉ l√† t·ª± l√†m ho·∫∑c mua nh∆∞ng kh√¥ng ph·∫£i s·∫£n ph·∫©m ƒë√≥ng g√≥i). √çt ho·∫∑c ho√†n to√†n kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn qu√°n ƒÉn.
    - Mukbang: Video t·∫≠p trung v√†o vi·ªác ƒÉn s·ªë l∆∞·ª£ng l·ªõn, ƒÉn to, ƒÉn g·∫ßn mic ho·∫∑c ƒÉn nhi·ªÅu m√≥n c√πng l√∫c, th∆∞·ªùng √≠t l·ªùi tho·∫°i.
    - N·∫•u ƒÉn: Video h∆∞·ªõng d·∫´n ho·∫∑c ghi l·∫°i qu√° tr√¨nh n·∫•u ƒÉn, c√≥ th·ªÉ ·ªü nh√†, ngo√†i tr·ªùi ho·∫∑c trong b·∫øp chuy√™n nghi·ªáp.
    - Kh√¥ng li√™n quan ·∫©m th·ª±c: Video kh√¥ng thu·ªôc b·∫•t k·ª≥ ch·ªß ƒë·ªÅ n√†o li√™n quan ƒë·∫øn ƒÉn u·ªëng, m√≥n ƒÉn, qu√°n ƒÉn ho·∫∑c tr·∫£i nghi·ªám ·∫©m th·ª±c.

    Y√™u c·∫ßu nghi√™m ng·∫∑t:

    1. Ch·ªâ s·ª≠ d·ª•ng ƒë√∫ng c√°c tr∆∞·ªùng v√† nh√£n (label) ƒë∆∞·ª£c li·ªát k√™ trong schema. Kh√¥ng ƒë∆∞·ª£c t·∫°o nh√£n m·ªõi.
    2. Ch·ªâ g√°n nh√£n cho nh·ªØng tr∆∞·ªùng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p r√µ r√†ng ho·∫∑c c√≥ th·ªÉ suy lu·∫≠n tr·ª±c ti·∫øp, h·ª£p l√Ω t·ª´ m√¥ t·∫£ c·ªßa ng∆∞·ªùi d√πng.
    3. Tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c suy di·ªÖn ch·ªß quan ho·∫∑c g√°n nh√£n theo c·∫£m t√≠nh. N·∫øu ng∆∞·ªùi d√πng kh√¥ng ƒë·ªÅ c·∫≠p ho·∫∑c kh√¥ng g·ª£i √Ω r√µ r√†ng, th√¨ kh√¥ng tr·∫£ v·ªÅ tr∆∞·ªùng ƒë√≥. (V√≠ d·ª• kh√¥ng suy lu·∫≠n ra c√°ch tone_of_voice d·ª±a tr√™n t√¥ng gi·ªçng c·ªßa ng∆∞·ªùi d√πng m√† ch·ªâ tr√≠ch ra khi ng∆∞·ªùi d√πng c√≥ ƒë·ªÅ c·∫≠p c·ª• th·ªÉ)
    4. N·∫øu ch·ªâ c√≥ m·ªôt v√†i tr∆∞·ªùng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p, ch·ªâ tr·∫£ v·ªÅ c√°c tr∆∞·ªùng ƒë√≥.
    5. S·ª≠ d·ª•ng tool ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ƒë·ªÉ cho ra k·∫øt qu·∫£
    """

    prompt = "D·ª±a tr√™n mi√™u t·∫£ c·ªßa ng∆∞·ªùi d√πng v·ªÅ video h·ªç mu·ªën th·ª±c hi·ªán, ti·∫øn h√†nh g√°n nh√£n cho c√°c tr∆∞·ªùng ƒë∆∞·ª£c ƒë·ªãnh tr∆∞·ªõc.\n\n" + \
        f"Mi√™u t·∫£: {user_description}"

    # Configure the client and tools

    tools = types.Tool(function_declarations=[annotate_user_desc_function])
    config = types.GenerateContentConfig(
        tools=[tools],
        # system_instruction=system_instruction,
        temperature=0.1,
        top_k=15,
        top_p=0.9
    )
    # Send request with function declarations
    response_filter = client.models.generate_content(
        model="gemini-2.0-flash",
        # model=model,
        contents=[system_instruction, prompt],
        config=config,
    )

    tool_call = response_filter.candidates[0].content.parts[0].function_call

    return tool_call.args if tool_call else None


def format_transcript_desc_examples(user_desc_filter_df, min_count=20):
    today = pd.Timestamp.now(tz='Asia/Ho_Chi_Minh')

    # T√≠nh s·ªë ng√†y k·ªÉ t·ª´ khi t·∫°o video
    user_desc_filter_df['days_since'] = (
        today - user_desc_filter_df['createTime']).dt.days
    alpha = 0.7
    user_desc_filter_df['score'] = user_desc_filter_df['statsV2.playCount'] / \
        ((user_desc_filter_df['days_since'] + 1) ** alpha)
    sorted_df = user_desc_filter_df.sort_values(by='score', ascending=False)
    example_df = sorted_df.head(min_count)

    def create_examples(df, col):
        return "\n\n".join(
            [f"{i}. {t}" for i, t in enumerate(df[col], 1)]
        )

    transcript_sample_text = create_examples(example_df, 'transcript')
    desc_sample_text = create_examples(example_df, 'desc')
    return transcript_sample_text, desc_sample_text


def generate_plain_script(
        user_input, transcript_sample_text, word_count, client, model, max_output_tokens=2000):
    prompt_plain_script = f"""
    B·∫°n l√† chuy√™n gia vi·∫øt k·ªãch b·∫£n video TikTok trong lƒ©nh v·ª±c ·∫©m th·ª±c.

    H√£y vi·∫øt m·ªôt k·ªãch b·∫£n video TikTok d·∫°ng **l·ªùi tho·∫°i t·ª± nhi√™n** d·ª±a tr√™n **c√°c transcript m·∫´u b√™n d∆∞·ªõi** v√† **m√¥ t·∫£ m√≥n ƒÉn t·ª´ ng∆∞·ªùi d√πng**.

    **Y√™u c·∫ßu:**
    - K·ªãch b·∫£n c√≥ ƒë·ªô d√†i kho·∫£ng **{word_count} t·ª´**, kh√¥ng ƒë∆∞·ª£c ch√™nh l·ªách qu√° 100 t·ª´.
    - Vi·∫øt theo d·∫°ng **l·ªùi tho·∫°i t·ª± nhi√™n**, nh∆∞ th·ªÉ ƒëang n√≥i trong video TikTok.
    - **Kh√¥ng chia ph·∫ßn**, **kh√¥ng th√™m ti√™u ƒë·ªÅ**, **kh√¥ng m·ªü ngo·∫∑c gi·∫£i th√≠ch** ho·∫∑c m√¥ t·∫£ b·ªëi c·∫£nh.
    - **Kh√¥ng ch√®n ch√∫ th√≠ch** nh∆∞ (c·∫£nh quay), (h√¨nh ·∫£nh), (√¢m thanh).
    - S·ª≠ d·ª•ng **gi·ªçng ƒëi·ªáu, c√°ch n√≥i, t·ªëc ƒë·ªô, hook v√† CTA** t∆∞∆°ng t·ª± c√°c transcript m·∫´u.
    - ∆Øu ti√™n s·ª≠ d·ª•ng c·ª•m t·ª´ ƒë·ªùi th∆∞·ªùng, d·ªÖ viral nh∆∞ \"Tr·ªùi ∆°i ngon g√¨ ƒë√¢u lu√¥n √°\", \"ƒÉn l√† ghi·ªÅn\", v.v.

    ---

    **M√¥ t·∫£ t·ª´ ng∆∞·ªùi d√πng:**
    {user_input}

    **C√°c transcript m·∫´u ƒë·ªÉ tham kh·∫£o phong c√°ch vi·∫øt:**
    {transcript_sample_text}
    """
    response_plain_script = client.models.generate_content(
        # model="gemini-2.0-flash-thinking-exp-1219",
        # model="gemini-2.0-flash",
        model=model,
        contents=[prompt_plain_script],
        config={'maxOutputTokens': max_output_tokens},
    )

    print(response_plain_script.usage_metadata)
    return response_plain_script.text


def format_script_with_gemini(plain_script, desc_sample_text, mean_word_per_second, mean_hashtag_count, top_10_cat_hashtags_text, client, model):
    script_seconds = len(plain_script.split()) / (mean_word_per_second)
    print("output script words:",  len(plain_script.split()))
    print("output script seconds:",  script_seconds)
    response_structured_script_schema = {
        "type": "object",
        "properties": {
            "video_description": {
                "type": "string",
                "description": f"M√¥ t·∫£ video k√®m theo {mean_hashtag_count} hashtag, vi·∫øt d·ª±a tr√™n n·ªôi dung k·ªãch b·∫£n, c√°c ƒëo·∫°n m√¥ t·∫£ m·∫´u v√† top 10 hashtag ƒë∆∞·ª£c d√πng nhi·ªÅu nh·∫•t."
            },
            "duration": {
                "type": "string",
                "description": "ƒê·ªô d√†i d·ª± ki·∫øn c·ªßa video, ƒë·ªãnh d·∫°ng l√† '<x> ph√∫t <y> gi√¢y'."
            },
            "setting": {
                "type": "string",
                "description": "B·ªëi c·∫£nh ho·∫∑c ƒë·ªãa ƒëi·ªÉm ghi h√¨nh, m√¥ t·∫£ ng·∫Øn g·ªçn."
            },
            "characters": {
                "type": "string",
                "description": "Nh√¢n v·∫≠t xu·∫•t hi·ªán trong video, m√¥ t·∫£ ng·∫Øn g·ªçn."
            },
            "main_content": {
                "type": "array",
                "description": "Danh s√°ch c√°c b∆∞·ªõc/n·ªôi dung ch√≠nh c·ªßa video ƒë√£ ƒë∆∞·ª£c chia nh·ªè.",
                "items": {
                    "type": "object",
                    "required": ["time_range", "title", "visual_description", "dialogue"],
                    "properties": {
                        "time_range": {
                            "type": "string",
                            "description": "Kho·∫£ng th·ªùi gian c·ªßa ƒëo·∫°n, v√≠ d·ª•: '0:00-0:15'"
                        },
                        "title": {
                            "type": "string",
                            "description": "T√™n b∆∞·ªõc/ph·∫ßn, v√≠ d·ª•: 'Gi·ªõi thi·ªáu m√≥n ƒÉn'"
                        },
                        "visual_description": {
                            "type": "string",
                            "description": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ h√¨nh ·∫£nh c·∫ßn quay."
                        },
                        "dialogue": {
                            "type": "string",
                            "description": "L·ªùi tho·∫°i g·ªëc t·ª´ k·ªãch b·∫£n plain, ƒë∆∞·ª£c gi·ªØ nguy√™n."
                        }
                    }
                }
            }
        },
        "required": ["video_description", "duration", "setting", "characters", "main_content"]
    }

    prompt_structured_script = f"""
    B·∫°n l√† chuy√™n gia vi·∫øt k·ªãch b·∫£n TikTok ·∫©m th·ª±c.

    H√£y chuy·ªÉn k·ªãch b·∫£n d·∫°ng plain d∆∞·ªõi ƒë√¢y th√†nh format theo schema JSON sau, gi·ªØ nguy√™n l·ªùi tho·∫°i g·ªëc, chia nh·ªè theo t·ª´ng b∆∞·ªõc n·ªôi dung nh∆∞ m·ªü ƒë·∫ßu, m√¥ t·∫£ m√≥n, c·∫£m nh·∫≠n, CTA,...

    Th√¥ng tin th√™m:
    - duration: {int(script_seconds // 60)} ph√∫t {int(script_seconds % 60)} gi√¢y

    Top 10 hashtag ƒë∆∞·ª£c s·ª≠ d·ª•ng nhi·ªÅu nh·∫•t: {top_10_cat_hashtags_text}

    C√°c ƒëo·∫°n m√¥ t·∫£ video m·∫´u:

    {desc_sample_text}

    K·ªãch b·∫£n plain:

    {plain_script}
    """
    # - L·ªìng gh√©p c·∫£m x√∫c m·∫°nh (s·ªëc, ti·∫øc, m√™ m·∫©n, chill...) ƒë·ªÉ tƒÉng t√≠nh cu·ªën h√∫t
    # - Gi·ªØ nh·ªãp ƒëi·ªáu t·ª± nhi√™n, mang phong c√°ch vƒÉn n√≥i, kh√¥ng vi·∫øt theo ki·ªÉu vƒÉn vi·∫øt

    response_structured_script = client.models.generate_content(
        model="gemini-2.0-flash",
        # model=model,
        contents=[prompt_structured_script],
        config={
            'response_mime_type': "application/json",
            'response_schema': response_structured_script_schema,
            # 'system_instruction': system_instruction,
            # 'temperature': 0.1

        }
    )

    try:
        response_dict = json.loads(response_structured_script.text)
    except json.decoder.JSONDecodeError as e:
        print("JSON decode error:", e)
        return None

    # script_seconds = len(response_plain_script.text.split()) / int(mean_word_per_second)
    # response_dict['duration'] = f"{int(script_seconds // 60)} ph√∫t {int(script_seconds % 60)} gi√¢y"
    # === T√≠nh l·∫°i time_range cho t·ª´ng ƒëo·∫°n main_content ===

    def seconds_to_mmss(sec):
        minutes = int(sec // 60)
        seconds = int(sec % 60)
        return f"{minutes}:{seconds:02d}"

    current_time = 0.0
    for step in response_dict.get("main_content", []):
        dialogue = step.get("dialogue", "")
        word_count = len(dialogue.split())
        duration = duration = round(word_count / mean_word_per_second, 2)

        start = seconds_to_mmss(current_time)
        end = seconds_to_mmss(current_time + duration)
        step["time_range"] = f"{start}-{end}"

        current_time += duration
    return response_dict


class ScriptGenerator:
    def __init__(self):
        self.init_page_config()
        self.init_session_state()
        self.model = self.get_model()
        self.features_df = self.load_data()
        self.client = genai.Client(api_key=API_KEY)

    def init_page_config(self):
        """Initialize Streamlit page configuration"""
        st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="wide",
                           initial_sidebar_state="expanded",)

    def init_session_state(self):
        """Initialize session state variables"""
        if 'formatted_script' not in st.session_state:
            st.session_state.formatted_script = None
        if 'updated_script_data' not in st.session_state:
            st.session_state.updated_script_data = None

    def get_model(self):
        """Get the selected AI model from sidebar"""
        return st.sidebar.selectbox(
            "Select AI Model:",
            AVAILABLE_MODELS,
            index=AVAILABLE_MODELS.index(DEFAULT_MODEL)
        )

    def load_data(self):
        """Load TikTok data with spinner"""
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu TikTok..."):
            features_df = load_data()

        if features_df is None:
            st.error("Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu TikTok. Vui l√≤ng th·ª≠ l·∫°i sau.")
            st.stop()

        return features_df

    def generate_script(self, user_description):
        """Generate script based on user description"""
        with st.spinner("Ph√¢n t√≠ch m√¥ t·∫£..."):
            # Generate labels from description
            label_dict = generate_labels_from_description(
                user_description, self.client, self.model)

            # Handle non-food content
            if label_dict is None:
                filtered_df = self.features_df
                filter_cat_df = self.features_df
            elif label_dict and label_dict['categories'] == 'Kh√¥ng li√™n quan ·∫©m th·ª±c':
                st.error(
                    "Y√™u c·∫ßu c·ªßa b·∫°n kh√¥ng li√™n quan ƒë·∫øn ·∫©m th·ª±c! Vui l√≤ng th·ª≠ l·∫°i v·ªõi m·ªôt m√¥ t·∫£ kh√°c.")
                return None
            else:
                # Extract duration if available
                duration = int(label_dict.pop("duration", None)) if label_dict.get(
                    "duration") is not None else None

                # Filter data based on labels
                filtered_df = filter_by_multiple_labels_unified(
                    self.features_df, label_dict, min_count=20)
                filter_cat_df = self.features_df[self.features_df['categories']
                                                 == label_dict['categories']]

            # Calculate statistics
            stats = self._calculate_statistics(filtered_df, filter_cat_df)

            # Use mean duration if not specified
            if duration is None:
                duration = stats['mean_duration']

            word_count = int(stats['mean_word_per_second'] * duration)
            max_output_tokens = int(word_count * 1.5)
            # max_output_tokens = 2000

            # Adjusted for better performance
            print(f"Duration: {duration}")
            print(f"Max Word Count: {word_count}")
            print(f"Max Output Token: {max_output_tokens}")

        # Generate and format script
        with st.spinner("T·∫°o k·ªãch b·∫£n th√¥..."):
            plain_script = generate_plain_script(
                user_description, stats['transcript_sample_text'], word_count, self.client, self.model, max_output_tokens)

        with st.spinner("ƒê·ªãnh d·∫°ng l·∫°i k·ªãch b·∫£n..."):
            formatted_script = format_script_with_gemini(
                plain_script,
                stats['desc_sample_text'],
                stats['mean_word_per_second'],
                stats['mean_hashtag_count'],
                stats['top_10_hashtags_text'],
                self.client,
                self.model
            )

            # Save to session state
            st.session_state.formatted_script = formatted_script
            st.session_state.updated_script_data = formatted_script.copy()

        return formatted_script

    def _calculate_statistics(self, filtered_df, filter_cat_df):
        """Calculate statistics from filtered dataframes"""
        stats = {
            'mean_word_count': int(filtered_df['transcript_word_count'].mean()),
            'mean_duration': int(filtered_df['video.duration'].mean()),
            'mean_word_per_second': filtered_df['word_per_second'].mean(),
            'mean_hashtag_count': int(filtered_df['hashtag_count'].mean()),
        }

        # Get top hashtags
        top_10_hashtags = filter_cat_df['hashtags'].explode(
        ).value_counts().head(10).index
        stats['top_10_hashtags_text'] = ', '.join(top_10_hashtags)

        # Get sample texts
        stats['transcript_sample_text'], stats['desc_sample_text'] = format_transcript_desc_examples(
            filtered_df, min_count=20)

        return stats

    def display_script_overview(self, script_data):
        """Display the script overview section"""
        st.markdown("### üìù T·ªïng quan video")
        st.markdown(
            f"**üé¨ M√¥ t·∫£ video:** {script_data.get('video_description', '')}")
        st.markdown(
            f"**‚è±Ô∏è ƒê·ªô d√†i d·ª± ki·∫øn:** {script_data.get('duration', '')}")
        st.markdown(f"**üìç B·ªëi c·∫£nh:** {script_data.get('setting', '')}")
        st.markdown(f"**üë§ Nh√¢n v·∫≠t:** {script_data.get('characters', '')}")
        st.markdown("---")

    def display_script_sections(self, script_data):
        """Display all script sections with edit functionality"""
        # Display overview
        self.display_script_overview(script_data)

        st.markdown("### üé¨ K·ªãch b·∫£n theo t·ª´ng ph·∫ßn")

        # Process section deletions
        self._process_section_deletions()

        # Display each section
        for idx, section in enumerate(st.session_state.updated_script_data.get("main_content", [])):
            self._display_single_section(idx, section)

        return st.session_state.updated_script_data

    def _process_section_deletions(self):
        """Process any pending section deletions"""
        sections_to_delete = []
        for idx in range(len(st.session_state.updated_script_data.get("main_content", []))):
            if st.session_state.get(f"delete_section_{idx}", False):
                sections_to_delete.append(idx)
                st.session_state[f"delete_section_{idx}"] = False

        for idx in sorted(sections_to_delete, reverse=True):
            st.session_state.updated_script_data["main_content"].pop(idx)

    def _display_single_section(self, idx, section):
        """Display a single script section with edit functionality"""
        key_prefix = f"sec_{idx}"

        # Initialize edit mode state if not exists
        if f"{key_prefix}_edit" not in st.session_state:
            st.session_state[f"{key_prefix}_edit"] = False

        edit_mode = st.session_state[f"{key_prefix}_edit"]
        default_text = f"[{section['time_range']}] {section['title']}"

        # Title row with edit/save buttons
        self._display_section_header(
            key_prefix, section, default_text, edit_mode)

        # Content section (visual and dialogue)
        self._display_section_content(key_prefix, section, edit_mode)

    def _display_section_header(self, key_prefix, section, default_text, edit_mode):
        """Display the section header with edit/save buttons"""
        col_title, col_btns = st.columns([9, 1])

        with col_title:
            if edit_mode:
                time_title_input = st.text_input(
                    "‚è±Ô∏è Th·ªùi gian & ti√™u ƒë·ªÅ", default_text,
                    key=f"{key_prefix}_time_title",
                    label_visibility="collapsed"
                )
            else:
                st.markdown(
                    f"""
                    <div style="background-color: #f0f0f0; padding: 8px 16px; border-radius: 6px;">
                        <strong>{default_text}</strong>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

        with col_btns:
            if not edit_mode:
                if st.button("‚úèÔ∏è", key=f"{key_prefix}_edit_btn", help="S·ª≠a", use_container_width=False):
                    st.session_state[f"{key_prefix}_edit"] = True
                    st.rerun()
            else:
                if st.button("‚úÖ", key=f"{key_prefix}_save_btn", help="L∆∞u", use_container_width=False):
                    self._save_section_edits(key_prefix, section, default_text)
                    st.session_state[f"{key_prefix}_edit"] = False
                    st.rerun()

    def _save_section_edits(self, key_prefix, section, default_text):
        """Save edits made to a section"""
        time_title_raw = st.session_state.get(
            f"{key_prefix}_time_title", default_text)
        if "]" in time_title_raw:
            time_part, title_part = time_title_raw.split("]", 1)
            section["time_range"] = time_part.strip(" [")
            section["title"] = title_part.strip()

    def _display_section_content(self, key_prefix, section, edit_mode):
        """Display the content (visual and dialogue) of a section"""
        col1, col2 = st.columns([1, 2])

        if edit_mode:
            with col1:
                st.markdown("üé• **C·∫£nh quay**")
                visual_input = st.text_area(
                    "üé• C·∫£nh quay", section['visual_description'],
                    key=f"{key_prefix}_visual", height=100,
                    label_visibility="collapsed"
                )
            with col2:
                st.markdown("üó£Ô∏è **L·ªùi tho·∫°i**")
                dialogue_input = st.text_area(
                    "üó£Ô∏è L·ªùi tho·∫°i", section['dialogue'],
                    key=f"{key_prefix}_dialogue", height=100,
                    label_visibility="collapsed"
                )

            # Update section values
            if f"{key_prefix}_visual" in st.session_state:
                section["visual_description"] = visual_input
            if f"{key_prefix}_dialogue" in st.session_state:
                section["dialogue"] = dialogue_input
        else:
            with col1:
                st.markdown("üé• **C·∫£nh quay**")
                st.markdown(section['visual_description'])
            with col2:
                st.markdown("üó£Ô∏è **L·ªùi tho·∫°i**")
                st.markdown(f"\"{section['dialogue']}\"")

    def run(self):
        """Main application flow"""
        st.title("‚úçÔ∏è T·∫°o k·ªãch b·∫£n TikTok")

        # Expandable section for description input
        with st.expander("üìù Nh·∫≠p m√¥ t·∫£ video", expanded=True):
            user_description = st.text_area(
                "M√¥ t·∫£ chi ti·∫øt v·ªÅ video TikTok b·∫°n mu·ªën t·∫°o:",
                placeholder="L√†m video TikTok h∆∞·ªõng d·∫´n n·∫•u m√¨ t√¥m tr·ª©ng si√™u nhanh, si√™u d·ªÖ cho sinh vi√™n. C·∫ßn nh·∫•n m·∫°nh v√†o s·ª± ti·ªán l·ª£i v√† h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc...",
                height=250  # Increased height for more space
            )

            # Add some example suggestions
            st.markdown("""
            **M·ªôt s·ªë chi ti·∫øt c√≥ th·ªÉ g·ª£i √Ω cho h·ªá th·ªëng:**
            - **M√≥n ƒÉn** v√† **m·ª•c ti√™u video** (review, n·∫•u, chia s·∫ª...)
            - **C√°ch tri·ªÉn khai** (k·ªÉ chuy·ªán, h∆∞·ªõng d·∫´n, review...)
            - **C√°ch m·ªü ƒë·∫ßu, gi·ªçng ƒëi·ªáu, t·ªëc ƒë·ªô video**
            - C√≥ **CTA** g√¨ kh√¥ng (comment, chia s·∫ª, gh√© qu√°n...)
            - Ai l√† **ng∆∞·ªùi xem** ch√≠nh (h·ªçc sinh, d√¢n vƒÉn ph√≤ng, n·ªôi tr·ª£...)
            
            **V√≠ d·ª•**: T√¥i mu·ªën l√†m video qu·∫£ng b√° cho s·∫£n ph·∫©m b√°nh tr√°ng ch·∫•m ph√¥ mai c·ªßa nh√† t√¥i, c√°ch n√≥i chuy·ªán g·∫ßn g≈©i, c√≥ h∆∞·ªõng d·∫´n c√°ch ƒÉn, gi·ªçng ƒëi·ªáu t·ª´ t·ªën.
            """)

            generate_button = st.button(
                "‚ú® T·∫°o k·ªãch b·∫£n", use_container_width=False)

        if generate_button and user_description:
            self.generate_script(user_description)
            st.header("üé¨ K·ªãch b·∫£n g·ª£i √Ω")

        # Display script if available
        if st.session_state.formatted_script:
            self.display_script_sections(st.session_state.formatted_script)


# Main execution
# if __name__ == "__main__":
app = ScriptGenerator()
app.run()
